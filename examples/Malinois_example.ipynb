{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6376937-da7d-445b-a691-e701dd478b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpramnist\n",
    "from mpramnist.Malinois.dataset import MalinoisDataset\n",
    "\n",
    "from mpramnist.models import BassetBranched\n",
    "\n",
    "from mpramnist.models import HumanLegNet\n",
    "from mpramnist.models import initialize_weights\n",
    "from mpramnist.trainers import LitModel_Malinois\n",
    "\n",
    "from mpramnist import transforms as t\n",
    "from mpramnist import target_transforms as t_t\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import pytorch_lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1d805-3499-48cc-83ac-d01f6593f6fd",
   "metadata": {},
   "source": [
    "# Initiate some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27bca7cc-41f9-4f00-b62b-ce25633bb5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_flank = MalinoisDataset.LEFT_FLANK\n",
    "right_flank = MalinoisDataset.RIGHT_FLANK\n",
    "BATCH_SIZE = 1076\n",
    "NUM_WORKERS = 103\n",
    "\n",
    "# default parametes\n",
    "activity_columns = ['HepG2','SKNSH', \"K562\"]\n",
    "stderr = ['K562_lfcSE', 'HepG2_lfcSE', 'SKNSH_lfcSE']\n",
    "seq = \"sequence\"\n",
    "stderr_threshold = 1.0,\n",
    "std_multiple_cut = 6.0,\n",
    "up_cutoff_move = 3.0,\n",
    "duplication_cutoff = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8faf383-22ac-4714-9583-423dd7fff0b2",
   "metadata": {},
   "source": [
    "# You wanna test original parametes?\n",
    "\n",
    "So use this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835eb05d-b12a-41c4-bfa4-d97d6d9e3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MalinoisDataset(split = \"train\",\n",
    "                                filtration = \"original\", # use \"original for author's parameters\"\n",
    "                                duplication_cutoff = 0.5,\n",
    "                                use_original_reverse_complement = True, # this parameter paddes sequences and does rev comp\n",
    "                                root = \"../data/\"\n",
    "                               )\n",
    "\n",
    "val_dataset = MalinoisDataset(split = \"val\",\n",
    "                              filtration = \"original\", root = \"../data/\") \n",
    "\n",
    "test_dataset = MalinoisDataset(split = \"test\",\n",
    "                              filtration = \"original\", root = \"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa37ad15-e20d-45c2-83c7-c51200445f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MalinoisDataset of size 1864176 (MpraDaraset)\n",
      "    Number of datapoints: 1864176\n",
      "    Used split fold: ['1', '2', '3', '4', '5', '6', '8', '9', '10', '11', '12', '14', '15', '16', '17', '18', '20', '22', 'Y']\n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 58809 (MpraDaraset)\n",
      "    Number of datapoints: 58809\n",
      "    Used split fold: ['19', '21', 'X']\n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 62582 (MpraDaraset)\n",
      "    Number of datapoints: 62582\n",
      "    Used split fold: ['7', '13']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(\"=\"*50)\n",
    "print(val_dataset)\n",
    "print(\"=\"*50)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60bfc9-e6e4-463e-9629-761cfafb491e",
   "metadata": {},
   "source": [
    "# Use your own parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e341a5-4a73-4bf8-9869-51b37723b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "train_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    t.ReverseComplement(0.5),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "val_test_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    t.Seq2Tensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7501fa55-08ba-4957-afbc-baf26e20635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "train_dataset = MalinoisDataset( \n",
    "                              split = \"train\", \n",
    "                              transform = train_transform,\n",
    "                              filtration = \"own\",\n",
    "                              duplication_cutoff = 0.5,\n",
    "                              root = \"../data/\") \n",
    "val_dataset = MalinoisDataset(\n",
    "                              split = \"val\",\n",
    "                              filtration = \"own\",\n",
    "                              transform = val_test_transform,\n",
    "                              root = \"../data/\") \n",
    "test_dataset = MalinoisDataset(\n",
    "                              split = \"test\", \n",
    "                              filtration = \"own\",\n",
    "                              transform = val_test_transform,\n",
    "                              root = \"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63379487-80ad-442b-9347-31545ba18246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 0.,  ..., 0., 1., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 1.,  ..., 1., 0., 0.]]),\n",
       " tensor([ 0.3796,  0.0046, -0.2444]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12efd406-f801-4f65-8d11-469ac448b306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MalinoisDataset of size 932088 (MpraDaraset)\n",
      "    Number of datapoints: 932088\n",
      "    Used split fold: ['1', '2', '3', '4', '5', '6', '8', '9', '10', '11', '12', '14', '15', '16', '17', '18', '20', '22', 'Y']\n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 58809 (MpraDaraset)\n",
      "    Number of datapoints: 58809\n",
      "    Used split fold: ['19', '21', 'X']\n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 62582 (MpraDaraset)\n",
      "    Number of datapoints: 62582\n",
      "    Used split fold: ['7', '13']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(\"=\"*50)\n",
    "print(val_dataset)\n",
    "print(\"=\"*50)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30060185-0182-4b75-b440-5de6a272a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = len(train_dataset[0][0])\n",
    "out_channels = len(activity_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236976ae-2492-45d0-8590-3b1b1db8d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = NUM_WORKERS)\n",
    "\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c59939-0ae2-47c7-bb67-5be3b4ef8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1KLmixed(nn.Module):\n",
    "    \n",
    "    def __init__(self, reduction='mean', alpha=1.0, beta=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.reduction = reduction\n",
    "        self.alpha = alpha\n",
    "        self.beta  = beta\n",
    "        \n",
    "        self.MSE = nn.L1Loss(reduction=reduction.replace('batch',''))\n",
    "        self.KL  = nn.KLDivLoss(reduction=reduction, log_target=True)\n",
    "        \n",
    "    def forward(self, preds, targets):\n",
    "        preds_log_prob  = preds   - torch.logsumexp(preds, dim=-1, keepdim=True)\n",
    "        target_log_prob = targets - torch.logsumexp(targets, dim=-1, keepdim=True)\n",
    "        \n",
    "        MSE_loss = self.MSE(preds, targets)\n",
    "        KL_loss  = self.KL(preds_log_prob, target_log_prob)\n",
    "        \n",
    "        combined_loss = MSE_loss.mul(self.alpha) + \\\n",
    "                        KL_loss.mul(self.beta)\n",
    "        \n",
    "        return combined_loss.div(self.alpha+self.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a5da072-2ec2-4e3b-941f-bc16c68302e6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Conv1dNorm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBassetBranched\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m seq_model \u001b[38;5;241m=\u001b[39m LitModel_Malinois(model \u001b[38;5;241m=\u001b[39m model, num_outputs \u001b[38;5;241m=\u001b[39m out_channels,\n\u001b[1;32m      4\u001b[0m                            loss \u001b[38;5;241m=\u001b[39m L1KLmixed(),\n\u001b[1;32m      5\u001b[0m                            weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-1\u001b[39m, lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-2\u001b[39m, print_each \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/5Term/mpramnist/models.py:471\u001b[0m, in \u001b[0;36mBassetBranched.__init__\u001b[0;34m(self, input_len, conv1_channels, conv1_kernel_size, conv2_channels, conv2_kernel_size, conv3_channels, conv3_kernel_size, n_linear_layers, linear_channels, linear_activation, linear_dropout_p, n_branched_layers, branched_channels, branched_activation, branched_dropout_p, n_outputs, use_batch_norm, use_weight_norm, loss_criterion, loss_args)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_weight_norm   \u001b[38;5;241m=\u001b[39m use_weight_norm\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad1  \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConstantPad1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_pad, \u001b[38;5;241m0.\u001b[39m)\n\u001b[0;32m--> 471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m \u001b[43mConv1dNorm\u001b[49m(\u001b[38;5;241m4\u001b[39m, \n\u001b[1;32m    472\u001b[0m                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_channels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_kernel_size, \n\u001b[1;32m    473\u001b[0m                         stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dilation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m    474\u001b[0m                         bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    475\u001b[0m                         batch_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_batch_norm, \n\u001b[1;32m    476\u001b[0m                         weight_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_weight_norm)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad2  \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConstantPad1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2_pad, \u001b[38;5;241m0.\u001b[39m)\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m Conv1dNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_channels, \n\u001b[1;32m    479\u001b[0m                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2_channels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2_kernel_size, \n\u001b[1;32m    480\u001b[0m                         stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dilation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m    481\u001b[0m                         bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    482\u001b[0m                         batch_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_batch_norm, \n\u001b[1;32m    483\u001b[0m                         weight_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_weight_norm)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Conv1dNorm' is not defined"
     ]
    }
   ],
   "source": [
    "model = BassetBranched()\n",
    "\n",
    "seq_model = LitModel_Malinois(model = model, num_outputs = out_channels,\n",
    "                           loss = L1KLmixed(),\n",
    "                           weight_decay = 1e-1, lr = 1e-2, print_each = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3688894-e167-4bea-b21a-b37daac3c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HumanLegNet(in_ch=in_channels,\n",
    "                     output_dim = out_channels,\n",
    "                     stem_ch=64,\n",
    "                     stem_ks=11,\n",
    "                     ef_ks=9,\n",
    "                     ef_block_sizes=[80, 96, 112, 128],\n",
    "                     pool_sizes=[2,2,2,2],\n",
    "                     resize_factor=4)\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "seq_model = LitModel_Malinois(model = model,\n",
    "                           loss = L1KLmixed(),\n",
    "                           weight_decay = 1e-2, lr = 7.05e-3, print_each = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0369bc30-8966-4d76-8816-37494df8d0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initialize a trainer\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    max_epochs=1,\n",
    "    gradient_clip_val=1,\n",
    "    precision='16-mixed', \n",
    "    enable_progress_bar = True,\n",
    "    num_sanity_val_steps=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e61afc00-ea49-4c2a-b5c1-dd24e1162eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name          | Type            | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model         | HumanLegNet     | 1.3 M  | train\n",
      "1 | loss          | L1KLmixed       | 0      | train\n",
      "2 | train_pearson | PearsonCorrCoef | 0      | train\n",
      "3 | val_pearson   | PearsonCorrCoef | 0      | train\n",
      "4 | test_pearson  | PearsonCorrCoef | 0      | train\n",
      "----------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.292     Total estimated model params size (MB)\n",
      "122       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5ed9c59284422ca440c1f1e0ac0748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                       | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nios/miniconda3/envs/mpramnist/lib/python3.12/site-packages/torch/nn/functional.py:3369: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                     | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85a5651c0354c8e8978c2b0cc211b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.2234857976436615\n",
      "      test_pearson          0.7964360117912292\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.2234857976436615, 'test_pearson': 0.7964360117912292}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.fit(seq_model,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)\n",
    "trainer.test(seq_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc1797-3a8f-49be-b5ad-326c54b2c42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mpramnist]",
   "language": "python",
   "name": "conda-env-mpramnist-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
