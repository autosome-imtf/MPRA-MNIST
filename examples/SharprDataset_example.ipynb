{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6376937-da7d-445b-a691-e701dd478b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpramnist\n",
    "from mpramnist.Sharpr.dataset import SharprDataset\n",
    "\n",
    "from mpramnist.models import HumanLegNet\n",
    "from mpramnist.models import initialize_weights\n",
    "from mpramnist.trainers import LitModel_Sharpr\n",
    "\n",
    "from mpramnist import transforms as t\n",
    "from mpramnist import target_transforms as t_t\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import lightning.pytorch as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from torchmetrics import PearsonCorrCoef\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1d805-3499-48cc-83ac-d01f6593f6fd",
   "metadata": {},
   "source": [
    "# Initiate some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27bca7cc-41f9-4f00-b62b-ce25633bb5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1096\n",
    "NUM_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5a9728-8f9d-4606-9d30-0b5453569e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k562_minp_rep1',\n",
       " 'k562_minp_rep2',\n",
       " 'k562_minp_avg',\n",
       " 'k562_sv40p_rep1',\n",
       " 'k562_sv40p_rep2',\n",
       " 'k562_sv40p_avg',\n",
       " 'hepg2_minp_rep1',\n",
       " 'hepg2_minp_rep2',\n",
       " 'hepg2_minp_avg',\n",
       " 'hepg2_sv40p_rep1',\n",
       " 'hepg2_sv40p_rep2',\n",
       " 'hepg2_sv40p_avg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SharprDataset.ACTIVITY_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835eb05d-b12a-41c4-bfa4-d97d6d9e3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "train_transform = t.Compose([\n",
    "    t.ReverseComplement(0.5),\n",
    "    t.Seq2Tensor(),\n",
    "])\n",
    "test_transform = t.Compose([\n",
    "    t.Seq2Tensor(), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ffd3e-9e6a-42c5-895c-4e4a5d64570e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "367428ab-8e2f-4003-8ff7-a48711c2cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "activity_columns = [ 'k562_minp_avg',\n",
    "                     'k562_sv40p_avg',\n",
    "                     'hepg2_minp_avg',\n",
    "                     'hepg2_sv40p_avg' ]\n",
    "train_dataset = SharprDataset(split=\"train\", activity_columns=activity_columns, transform=train_transform, root = \"../data/\")# for needed folds\n",
    "\n",
    "val_dataset = SharprDataset( split=\"val\",activity_columns=activity_columns, transform=test_transform, root = \"../data/\") # use \"val\" for default validation set\n",
    "\n",
    "test_dataset = SharprDataset( split=\"test\",activity_columns=activity_columns, transform=test_transform, root = \"../data/\") # use \"test\" for default test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9020e7f4-1fa4-433b-bfbb-e0ce6f40dab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset SharprDataset of size 457174 (MpraDaraset)\n",
      "    Number of datapoints: 457174\n",
      "    Used split fold: train\n",
      "==================================================\n",
      "Dataset SharprDataset of size 10130 (MpraDaraset)\n",
      "    Number of datapoints: 10130\n",
      "    Used split fold: val\n",
      "==================================================\n",
      "Dataset SharprDataset of size 10130 (MpraDaraset)\n",
      "    Number of datapoints: 10130\n",
      "    Used split fold: test\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(\"=\"*50)\n",
    "print(val_dataset)\n",
    "print(\"=\"*50)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fbc1bc1-4979-4ca4-afb8-c56394b274f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = NUM_WORKERS)\n",
    "\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "624d91cb-1374-470d-aa32-aea4c0273e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = len(train_dataset[0][0])\n",
    "out_channels = len(activity_columns)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a2d6262-6859-42b8-9612-2c69a54aa9c1",
   "metadata": {},
   "source": [
    "# search good lr\n",
    "model = HumanLegNet(in_ch=in_channels,\n",
    "                     output_dim = out_channels,\n",
    "                     stem_ch=64,\n",
    "                     stem_ks=11,\n",
    "                     ef_ks=9,\n",
    "                     ef_block_sizes=[256, 128, 128, 128, 64, 64],\n",
    "                     pool_sizes=[2,2,2,2,2,2],\n",
    "                     resize_factor=4)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-7, weight_decay = 1e-4)\n",
    "criterion = nn.MSELoss() \n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(train_loader, start_lr=1e-7, end_lr=10, num_iter=100)\n",
    "\n",
    "lr_finder.plot()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3f35a08-d9bb-427b-ad30-04b7bc5ccbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HumanLegNet(in_ch=in_channels,\n",
    "                     output_dim = out_channels,\n",
    "                     stem_ch=64,\n",
    "                     stem_ks=11,\n",
    "                     ef_ks=9,\n",
    "                     ef_block_sizes=[80, 96, 112, 128],\n",
    "                     pool_sizes=[2,2,2,2],\n",
    "                     resize_factor=4)\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "seq_model = LitModel_Sharpr(model = model,\n",
    "                           loss = nn.MSELoss(), \n",
    "                            num_outputs = out_channels,\n",
    "                           activity_columns = activity_columns,\n",
    "                           weight_decay = 1e-1, lr = 1e-2, print_each = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f7a27f5-1d55-48bd-b7af-63e505fd0976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='k562_minp_avg', \n",
    "        mode='max',  \n",
    "        save_top_k=1,\n",
    "        save_last=False\n",
    "    )\n",
    "# Initialize a trainer\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    max_epochs=35,\n",
    "    gradient_clip_val=1,\n",
    "    precision='16-mixed', \n",
    "    enable_progress_bar = False,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06844ac1-57bf-4545-826a-8c879205d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name          | Type            | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model         | HumanLegNet     | 1.3 M  | train\n",
      "1 | loss          | MSELoss         | 0      | train\n",
      "2 | train_pearson | PearsonCorrCoef | 0      | train\n",
      "3 | val_pearson   | PearsonCorrCoef | 0      | train\n",
      "4 | test_pearson  | PearsonCorrCoef | 0      | train\n",
      "----------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.293     Total estimated model params size (MB)\n",
      "120       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 0 | Val Loss: 0.96289 | Val Pearson: k562_minp_avg : 0.2937263548374176, k562_sv40p_avg : 0.13820180296897888, hepg2_minp_avg : 0.19366231560707092, hepg2_sv40p_avg : 0.20273815095424652, | Train Pearson: 0.25051 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 1 | Val Loss: 1.18851 | Val Pearson: k562_minp_avg : 0.18446898460388184, k562_sv40p_avg : 0.11782119423151016, hepg2_minp_avg : 0.17350295186042786, hepg2_sv40p_avg : 0.22807031869888306, | Train Pearson: 0.32296 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 2 | Val Loss: 0.96305 | Val Pearson: k562_minp_avg : 0.29433003067970276, k562_sv40p_avg : 0.11501581221818924, hepg2_minp_avg : 0.23593106865882874, hepg2_sv40p_avg : 0.24449744820594788, | Train Pearson: 0.34426 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 3 | Val Loss: 0.99712 | Val Pearson: k562_minp_avg : 0.2872559726238251, k562_sv40p_avg : 0.12927094101905823, hepg2_minp_avg : 0.23103459179401398, hepg2_sv40p_avg : 0.2542688250541687, | Train Pearson: 0.35216 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 4 | Val Loss: 0.93003 | Val Pearson: k562_minp_avg : 0.336182564496994, k562_sv40p_avg : 0.16218820214271545, hepg2_minp_avg : 0.27894464135169983, hepg2_sv40p_avg : 0.3154160678386688, | Train Pearson: 0.35706 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 5 | Val Loss: 0.93388 | Val Pearson: k562_minp_avg : 0.33538055419921875, k562_sv40p_avg : 0.1491406410932541, hepg2_minp_avg : 0.2515701949596405, hepg2_sv40p_avg : 0.28414878249168396, | Train Pearson: 0.35895 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 6 | Val Loss: 0.95377 | Val Pearson: k562_minp_avg : 0.30761292576789856, k562_sv40p_avg : 0.15326495468616486, hepg2_minp_avg : 0.21686498820781708, hepg2_sv40p_avg : 0.23026122152805328, | Train Pearson: 0.36116 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 7 | Val Loss: 0.92879 | Val Pearson: k562_minp_avg : 0.3364885747432709, k562_sv40p_avg : 0.17850297689437866, hepg2_minp_avg : 0.26187291741371155, hepg2_sv40p_avg : 0.28402507305145264, | Train Pearson: 0.36063 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 8 | Val Loss: 1.00176 | Val Pearson: k562_minp_avg : 0.3170764148235321, k562_sv40p_avg : 0.15301069617271423, hepg2_minp_avg : 0.26223474740982056, hepg2_sv40p_avg : 0.28002455830574036, | Train Pearson: 0.36185 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 9 | Val Loss: 0.95735 | Val Pearson: k562_minp_avg : 0.33062437176704407, k562_sv40p_avg : 0.18289782106876373, hepg2_minp_avg : 0.2642950415611267, hepg2_sv40p_avg : 0.3255540430545807, | Train Pearson: 0.36493 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 10 | Val Loss: 1.02388 | Val Pearson: k562_minp_avg : 0.30240532755851746, k562_sv40p_avg : 0.16664111614227295, hepg2_minp_avg : 0.25035345554351807, hepg2_sv40p_avg : 0.27347004413604736, | Train Pearson: 0.36746 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 11 | Val Loss: 0.94994 | Val Pearson: k562_minp_avg : 0.33858126401901245, k562_sv40p_avg : 0.17987802624702454, hepg2_minp_avg : 0.26091477274894714, hepg2_sv40p_avg : 0.28319141268730164, | Train Pearson: 0.36910 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 12 | Val Loss: 0.92747 | Val Pearson: k562_minp_avg : 0.3246047794818878, k562_sv40p_avg : 0.1886598914861679, hepg2_minp_avg : 0.28521350026130676, hepg2_sv40p_avg : 0.3169820308685303, | Train Pearson: 0.37407 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 13 | Val Loss: 0.95068 | Val Pearson: k562_minp_avg : 0.3324333131313324, k562_sv40p_avg : 0.16202419996261597, hepg2_minp_avg : 0.2759473919868469, hepg2_sv40p_avg : 0.31070417165756226, | Train Pearson: 0.37763 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 14 | Val Loss: 0.95151 | Val Pearson: k562_minp_avg : 0.28584617376327515, k562_sv40p_avg : 0.1671813428401947, hepg2_minp_avg : 0.28504008054733276, hepg2_sv40p_avg : 0.32329055666923523, | Train Pearson: 0.38044 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 15 | Val Loss: 0.97732 | Val Pearson: k562_minp_avg : 0.2846543490886688, k562_sv40p_avg : 0.18119272589683533, hepg2_minp_avg : 0.24056734144687653, hepg2_sv40p_avg : 0.2873402237892151, | Train Pearson: 0.38383 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 16 | Val Loss: 1.03391 | Val Pearson: k562_minp_avg : 0.33369457721710205, k562_sv40p_avg : 0.17377448081970215, hepg2_minp_avg : 0.2792900502681732, hepg2_sv40p_avg : 0.3129311203956604, | Train Pearson: 0.38704 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 17 | Val Loss: 0.94976 | Val Pearson: k562_minp_avg : 0.3219001591205597, k562_sv40p_avg : 0.18643344938755035, hepg2_minp_avg : 0.3029049336910248, hepg2_sv40p_avg : 0.3484361171722412, | Train Pearson: 0.39206 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 18 | Val Loss: 0.99727 | Val Pearson: k562_minp_avg : 0.3345928490161896, k562_sv40p_avg : 0.1845385730266571, hepg2_minp_avg : 0.2678638696670532, hepg2_sv40p_avg : 0.2483801543712616, | Train Pearson: 0.39617 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 19 | Val Loss: 1.12912 | Val Pearson: k562_minp_avg : 0.2610767185688019, k562_sv40p_avg : 0.14197157323360443, hepg2_minp_avg : 0.2325793355703354, hepg2_sv40p_avg : 0.29077866673469543, | Train Pearson: 0.40030 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 20 | Val Loss: 1.15425 | Val Pearson: k562_minp_avg : 0.31334200501441956, k562_sv40p_avg : 0.1543407440185547, hepg2_minp_avg : 0.2353510558605194, hepg2_sv40p_avg : 0.25333985686302185, | Train Pearson: 0.40652 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 21 | Val Loss: 1.02712 | Val Pearson: k562_minp_avg : 0.2939291298389435, k562_sv40p_avg : 0.1698881834745407, hepg2_minp_avg : 0.26359716057777405, hepg2_sv40p_avg : 0.2751195728778839, | Train Pearson: 0.41270 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 22 | Val Loss: 1.04663 | Val Pearson: k562_minp_avg : 0.3131842315196991, k562_sv40p_avg : 0.1394885629415512, hepg2_minp_avg : 0.2289966195821762, hepg2_sv40p_avg : 0.27827176451683044, | Train Pearson: 0.41818 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 23 | Val Loss: 0.94262 | Val Pearson: k562_minp_avg : 0.3256392478942871, k562_sv40p_avg : 0.1557924747467041, hepg2_minp_avg : 0.2892443835735321, hepg2_sv40p_avg : 0.2984880805015564, | Train Pearson: 0.42496 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 24 | Val Loss: 0.99218 | Val Pearson: k562_minp_avg : 0.30513158440589905, k562_sv40p_avg : 0.1360417753458023, hepg2_minp_avg : 0.2615920305252075, hepg2_sv40p_avg : 0.2743845582008362, | Train Pearson: 0.43312 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 25 | Val Loss: 1.01570 | Val Pearson: k562_minp_avg : 0.2940763235092163, k562_sv40p_avg : 0.1524057388305664, hepg2_minp_avg : 0.2862853705883026, hepg2_sv40p_avg : 0.3059549331665039, | Train Pearson: 0.44172 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 26 | Val Loss: 0.91178 | Val Pearson: k562_minp_avg : 0.35772645473480225, k562_sv40p_avg : 0.20289939641952515, hepg2_minp_avg : 0.3244853615760803, hepg2_sv40p_avg : 0.34522950649261475, | Train Pearson: 0.45046 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 27 | Val Loss: 0.93752 | Val Pearson: k562_minp_avg : 0.3816615641117096, k562_sv40p_avg : 0.20246057212352753, hepg2_minp_avg : 0.303612619638443, hepg2_sv40p_avg : 0.29538536071777344, | Train Pearson: 0.46091 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 28 | Val Loss: 0.91548 | Val Pearson: k562_minp_avg : 0.36566656827926636, k562_sv40p_avg : 0.19486810266971588, hepg2_minp_avg : 0.31187403202056885, hepg2_sv40p_avg : 0.30602967739105225, | Train Pearson: 0.47293 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 29 | Val Loss: 0.91612 | Val Pearson: k562_minp_avg : 0.37899303436279297, k562_sv40p_avg : 0.19944466650485992, hepg2_minp_avg : 0.3255256116390228, hepg2_sv40p_avg : 0.322399765253067, | Train Pearson: 0.48449 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 30 | Val Loss: 0.92911 | Val Pearson: k562_minp_avg : 0.37146010994911194, k562_sv40p_avg : 0.200232595205307, hepg2_minp_avg : 0.30945640802383423, hepg2_sv40p_avg : 0.29894402623176575, | Train Pearson: 0.49744 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 31 | Val Loss: 0.92600 | Val Pearson: k562_minp_avg : 0.37505313754081726, k562_sv40p_avg : 0.19020362198352814, hepg2_minp_avg : 0.30343419313430786, hepg2_sv40p_avg : 0.29705357551574707, | Train Pearson: 0.50928 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 32 | Val Loss: 0.93456 | Val Pearson: k562_minp_avg : 0.37700939178466797, k562_sv40p_avg : 0.1952926367521286, hepg2_minp_avg : 0.3034059405326843, hepg2_sv40p_avg : 0.2948955297470093, | Train Pearson: 0.51928 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 33 | Val Loss: 0.93558 | Val Pearson: k562_minp_avg : 0.3718912899494171, k562_sv40p_avg : 0.18836519122123718, hepg2_minp_avg : 0.30076727271080017, hepg2_sv40p_avg : 0.29258155822753906, | Train Pearson: 0.52540 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 34 | Val Loss: 0.93954 | Val Pearson: k562_minp_avg : 0.3709847927093506, k562_sv40p_avg : 0.1886509656906128, hepg2_minp_avg : 0.300819456577301, hepg2_sv40p_avg : 0.2899799048900604, | Train Pearson: 0.52925 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.fit(seq_model,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e61afc00-ea49-4c2a-b5c1-dd24e1162eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        Test metric                 DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_loss               0.937516987323761\n",
      "test_pearson_hepg2_minp_avg      0.303612619638443\n",
      "test_pearson_hepg2_sv40p_avg    0.29538536071777344\n",
      " test_pearson_k562_minp_avg      0.3816615641117096\n",
      "test_pearson_k562_sv40p_avg     0.20246057212352753\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.937516987323761,\n",
       "  'test_pearson_k562_minp_avg': 0.3816615641117096,\n",
       "  'test_pearson_k562_sv40p_avg': 0.20246057212352753,\n",
       "  'test_pearson_hepg2_minp_avg': 0.303612619638443,\n",
       "  'test_pearson_hepg2_sv40p_avg': 0.29538536071777344}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path = checkpoint_callback.best_model_path\n",
    "seq_model = LitModel_Sharpr.load_from_checkpoint(\n",
    "    best_model_path,\n",
    "    model = model,\n",
    "    loss = nn.MSELoss(), \n",
    "    num_outputs = out_channels,\n",
    "    activity_columns = activity_columns,\n",
    "    weight_decay = 1e-1, lr = 1e-2, print_each = 1)\n",
    "trainer.test(seq_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab88c058-4a36-4567-9ae0-c1d749dfe265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaned_prediction(forw, rev, trainer, seq_model, name):\n",
    "\n",
    "    predictions_forw = trainer.predict(seq_model, dataloaders = forw)\n",
    "    targets = torch.cat([pred[\"target\"] for pred in predictions_forw])\n",
    "    y_preds_forw = torch.cat([pred[\"predicted\"] for pred in predictions_forw])\n",
    "    \n",
    "    predictions_rev = trainer.predict(seq_model, dataloaders = rev)\n",
    "    y_preds_rev = torch.cat([pred[\"predicted\"] for pred in predictions_rev])\n",
    "    \n",
    "    mean_forw = torch.mean(torch.stack([y_preds_forw, y_preds_rev]), dim=0)\n",
    "    \n",
    "    pears = PearsonCorrCoef(num_outputs = out_channels)\n",
    "    print(name + \" Pearson correlation\")\n",
    "    \n",
    "    return pears(mean_forw, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f3a9233-04bd-4255-96ee-54ff38fdad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpr Pearson correlation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4016, 0.2175, 0.3214, 0.3212])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forw_transform = t.Compose([\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "rev_transform = t.Compose([\n",
    "    t.ReverseComplement(1),\n",
    "    t.Seq2Tensor(),\n",
    "])\n",
    "\n",
    "test_forw = SharprDataset(split = \"test\", activity_columns=activity_columns, transform = forw_transform, root = \"../data/\")\n",
    "test_rev = SharprDataset(split = \"test\",activity_columns=activity_columns, transform = rev_transform, root = \"../data/\")\n",
    "\n",
    "forw = data.DataLoader(dataset = test_forw, batch_size = BATCH_SIZE, shuffle = False, num_workers = NUM_WORKERS, pin_memory = True)\n",
    "rev = data.DataLoader(dataset = test_rev, batch_size = BATCH_SIZE, shuffle = False, num_workers = NUM_WORKERS, pin_memory = True)\n",
    "\n",
    "meaned_prediction(forw, rev, trainer, seq_model, \"Sharpr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6024ed6-c2bf-4794-8924-179dda60f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = checkpoint_callback.best_model_path\n",
    "seq_model_finetune = LitModel_Sharpr.load_from_checkpoint(\n",
    "    best_model_path,\n",
    "    model = model,\n",
    "    loss = nn.MSELoss(), \n",
    "    num_outputs = out_channels,\n",
    "    activity_columns = activity_columns,\n",
    "    weight_decay = 1e-5, lr = 1e-4, print_each = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f140b787-9170-4604-b3d4-c4bfc2a94916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback_finetune = ModelCheckpoint(\n",
    "        monitor='k562_minp_avg', \n",
    "        mode='max',  \n",
    "        save_top_k=1,\n",
    "        save_last=False\n",
    "    )\n",
    "# Initialize a trainer\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    max_epochs=5,\n",
    "    gradient_clip_val=1,\n",
    "    precision='16-mixed', \n",
    "    enable_progress_bar = False,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback_finetune]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ffb9b44-4d94-41d3-9c1a-c935d724258a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name          | Type            | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model         | HumanLegNet     | 1.3 M  | eval \n",
      "1 | loss          | MSELoss         | 0      | train\n",
      "2 | train_pearson | PearsonCorrCoef | 0      | train\n",
      "3 | val_pearson   | PearsonCorrCoef | 0      | train\n",
      "4 | test_pearson  | PearsonCorrCoef | 0      | train\n",
      "----------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.293     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "116       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 0 | Val Loss: 0.90574 | Val Pearson: k562_minp_avg : 0.3833366334438324, k562_sv40p_avg : 0.20157833397388458, hepg2_minp_avg : 0.32867172360420227, hepg2_sv40p_avg : 0.33414044976234436, | Train Pearson: 0.47960 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 1 | Val Loss: 0.91019 | Val Pearson: k562_minp_avg : 0.38144758343696594, k562_sv40p_avg : 0.1973334103822708, hepg2_minp_avg : 0.3172764778137207, hepg2_sv40p_avg : 0.3268129229545593, | Train Pearson: 0.48596 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 2 | Val Loss: 0.91329 | Val Pearson: k562_minp_avg : 0.380451500415802, k562_sv40p_avg : 0.19945082068443298, hepg2_minp_avg : 0.31992286443710327, hepg2_sv40p_avg : 0.32243484258651733, | Train Pearson: 0.48934 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 3 | Val Loss: 0.91313 | Val Pearson: k562_minp_avg : 0.38312479853630066, k562_sv40p_avg : 0.19957375526428223, hepg2_minp_avg : 0.32049477100372314, hepg2_sv40p_avg : 0.32037416100502014, | Train Pearson: 0.49265 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch: 4 | Val Loss: 0.91263 | Val Pearson: k562_minp_avg : 0.3841629922389984, k562_sv40p_avg : 0.1978197544813156, hepg2_minp_avg : 0.31945309042930603, hepg2_sv40p_avg : 0.3190837502479553, | Train Pearson: 0.49434 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.fit(seq_model_finetune,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1fcdf51-a525-414f-b197-33216ad16f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        Test metric                 DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_loss               0.9126330614089966\n",
      "test_pearson_hepg2_minp_avg     0.31945309042930603\n",
      "test_pearson_hepg2_sv40p_avg     0.3190837502479553\n",
      " test_pearson_k562_minp_avg      0.3841629922389984\n",
      "test_pearson_k562_sv40p_avg      0.1978197544813156\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.9126330614089966,\n",
       "  'test_pearson_k562_minp_avg': 0.3841629922389984,\n",
       "  'test_pearson_k562_sv40p_avg': 0.1978197544813156,\n",
       "  'test_pearson_hepg2_minp_avg': 0.31945309042930603,\n",
       "  'test_pearson_hepg2_sv40p_avg': 0.3190837502479553}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path = checkpoint_callback_finetune.best_model_path\n",
    "seq_model_finetune = LitModel_Sharpr.load_from_checkpoint(\n",
    "    best_model_path,\n",
    "    model = model,\n",
    "    loss = nn.MSELoss(), \n",
    "    num_outputs = out_channels,\n",
    "    activity_columns = activity_columns,\n",
    "    weight_decay = 1e-5, lr = 1e-4, print_each = 1)\n",
    "trainer.test(seq_model_finetune, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4cdd355-c5f2-4f3b-a95d-5bff338d1e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpr Pearson correlation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4083, 0.2182, 0.3536, 0.3561])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forw_transform = t.Compose([\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "rev_transform = t.Compose([\n",
    "    t.ReverseComplement(1),\n",
    "    t.Seq2Tensor(),\n",
    "])\n",
    "\n",
    "test_forw = SharprDataset(split = \"test\", activity_columns=activity_columns, transform = forw_transform, root = \"../data/\")\n",
    "test_rev = SharprDataset(split = \"test\",activity_columns=activity_columns, transform = rev_transform, root = \"../data/\")\n",
    "\n",
    "forw = data.DataLoader(dataset = test_forw, batch_size = BATCH_SIZE, shuffle = False, num_workers = NUM_WORKERS, pin_memory = True)\n",
    "rev = data.DataLoader(dataset = test_rev, batch_size = BATCH_SIZE, shuffle = False, num_workers = NUM_WORKERS, pin_memory = True)\n",
    "\n",
    "meaned_prediction(forw, rev, trainer, seq_model_finetune, \"Sharpr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21269b6-80b7-4220-9cbd-d1e77880337d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mpramnist]",
   "language": "python",
   "name": "conda-env-mpramnist-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
