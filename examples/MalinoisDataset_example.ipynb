{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9a8e6a-f156-47cd-ac97-5e2859b41671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nios/miniconda3/envs/mpra/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import mpramnist\n",
    "from mpramnist.malinoisdataset import MalinoisDataset\n",
    "\n",
    "import mpramnist.transforms as t\n",
    "import mpramnist.target_transforms as t_t\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchsummary import summary\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import tempfile\n",
    "import hypertune\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b4112e-6aa2-46cf-931c-3b514a1764a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_flank = MalinoisDataset.LEFT_FLANK\n",
    "right_flank = MalinoisDataset.RIGHT_FLANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557a30c7-88c1-4384-b2f8-a5b1dd6950f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1076\n",
    "NUM_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70bb49ad-0ba2-48f5-90b0-826581518c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a55df33-548e-456c-80a4-8275a6e1842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(x):\n",
    "    p_c = nn.Softmax(dim=1)(x)    \n",
    "    return torch.sum(- p_c * torch.log(p_c), axis=1)\n",
    "def pearson_correlation(x, y):\n",
    "    vx = x - torch.mean(x, dim=0)\n",
    "    vy = y - torch.mean(y, dim=0)\n",
    "    pearsons = torch.sum(vx * vy, dim=0) / (torch.sqrt(torch.sum(vx ** 2, dim=0)) * torch.sqrt(torch.sum(vy ** 2, dim=0)) + 1e-10)\n",
    "    return pearsons, torch.mean(pearsons)\n",
    "def _get_ranks(x):\n",
    "    tmp = x.argsort(dim=0)\n",
    "    ranks = torch.zeros_like(tmp)\n",
    "    if len(x.shape) > 1:\n",
    "        dims = x.shape[1]\n",
    "        for dim in range(dims):\n",
    "            ranks[tmp[:,dim], dim] = torch.arange(x.shape[0], layout=x.layout, device=x.device)\n",
    "    else:\n",
    "        ranks[tmp] = torch.arange(x.shape[0], layout=x.layout, device=x.device)\n",
    "    return ranks\n",
    "def spearman_correlation(x, y):\n",
    "    x_rank = _get_ranks(x).float()\n",
    "    y_rank = _get_ranks(y).float()\n",
    "    return pearson_correlation(x_rank, y_rank)\n",
    "\n",
    "def filter_state_dict(model, stashed_dict):\n",
    "    results_dict = { \n",
    "        'filtered_state_dict': {},\n",
    "        'passed_keys'  : [],\n",
    "        'removed_keys' : [],\n",
    "        'missing_keys' : [],\n",
    "        'unloaded_keys': []\n",
    "                   }\n",
    "    old_dict = model.state_dict()\n",
    "\n",
    "    for m_key, m_value in old_dict.items():\n",
    "        try:\n",
    "            \n",
    "            if old_dict[m_key].shape == stashed_dict[m_key].shape:\n",
    "                results_dict['filtered_state_dict'][m_key] = stashed_dict[m_key]\n",
    "                results_dict['passed_keys'].append(m_key)\n",
    "                print(f'Key {m_key} successfully matched', file=sys.stderr)\n",
    "                \n",
    "            else:\n",
    "                check_str = 'Size mismatch for key: {}, expected size {}, got {}' \\\n",
    "                              .format(m_key, old_dict[m_key].shape, stashed_dict[m_key].shape)\n",
    "                results_dict['removed_keys'].append(m_key)\n",
    "                print(check_str, file=sys.stderr)\n",
    "                \n",
    "        except KeyError:\n",
    "            results_dict['missing_keys'].append(m_key)\n",
    "            print(f'Missing key in dict: {m_key}', file=sys.stderr)\n",
    "            \n",
    "    for m_key, m_value in stashed_dict.items():\n",
    "        if m_key not in old_dict.keys():\n",
    "            check_str = 'Skipped loading key: {} of size {}' \\\n",
    "                           .format(m_key, m_value.shape)\n",
    "            results_dict['unloaded_keys'].append(m_key)\n",
    "            print(check_str, file=sys.stderr)\n",
    "            \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45620d1c-a03c-4fa2-a158-a3678a48a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1KLmixed(nn.Module):\n",
    "    \"\"\"\n",
    "    A custom loss module that combines L1 loss with Kullback-Leibler (KL) divergence loss.\n",
    "\n",
    "    Args:\n",
    "        reduction (str, optional): Specifies the reduction to apply to the losses. Default is 'mean'.\n",
    "        alpha (float, optional): Scaling factor for the L1 loss term. Default is 1.0.\n",
    "        beta (float, optional): Scaling factor for the KL divergence loss term. Default is 1.0.\n",
    "\n",
    "    Attributes:\n",
    "        reduction (str): The reduction method applied to the losses.\n",
    "        alpha (float): Scaling factor for the L1 loss term.\n",
    "        beta (float): Scaling factor for the KL divergence loss term.\n",
    "        MSE (nn.L1Loss): The L1 loss function.\n",
    "        KL (nn.KLDivLoss): The Kullback-Leibler divergence loss function.\n",
    "\n",
    "    Methods:\n",
    "        forward(preds, targets):\n",
    "            Calculate the combined loss by combining L1 and KL divergence losses.\n",
    "\n",
    "    Example:\n",
    "        loss_fn = L1KLmixed()\n",
    "        loss = loss_fn(predictions, targets)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, reduction='mean', alpha=1.0, beta=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.reduction = reduction\n",
    "        self.alpha = alpha\n",
    "        self.beta  = beta\n",
    "        \n",
    "        self.MSE = nn.L1Loss(reduction=reduction.replace('batch',''))\n",
    "        self.KL  = nn.KLDivLoss(reduction=reduction, log_target=True)\n",
    "        \n",
    "    def forward(self, preds, targets):\n",
    "        preds_log_prob  = preds   - torch.logsumexp(preds, dim=-1, keepdim=True)\n",
    "        target_log_prob = targets - torch.logsumexp(targets, dim=-1, keepdim=True)\n",
    "        \n",
    "        MSE_loss = self.MSE(preds, targets)\n",
    "        KL_loss  = self.KL(preds_log_prob, target_log_prob)\n",
    "        \n",
    "        combined_loss = MSE_loss.mul(self.alpha) + \\\n",
    "                        KL_loss.mul(self.beta)\n",
    "        \n",
    "        return combined_loss.div(self.alpha+self.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3d2f11-1b42-43df-9ef2-cb6278a0edc4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BranchedLinear(nn.Module):\n",
    "    def __init__(self, in_features, hidden_group_size, out_group_size, \n",
    "                 n_branches=1, n_layers=1, \n",
    "                 activation='ReLU', dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.hidden_group_size = hidden_group_size\n",
    "        self.out_group_size = out_group_size\n",
    "        self.n_branches = n_branches\n",
    "        self.n_layers   = n_layers\n",
    "        \n",
    "        self.branches = OrderedDict()\n",
    "        \n",
    "        self.nonlin  = getattr(nn, activation)()                               \n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        self.intake = RepeatLayer(1, n_branches)\n",
    "        cur_size = in_features\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            if i + 1 == n_layers:\n",
    "                setattr(self, f'branched_layer_{i+1}',  GroupedLinear(cur_size, out_group_size, n_branches))\n",
    "            else:\n",
    "                setattr(self, f'branched_layer_{i+1}',  GroupedLinear(cur_size, hidden_group_size, n_branches))\n",
    "            cur_size = hidden_group_size\n",
    "            \n",
    "    def forward(self, x):\n",
    "\n",
    "        hook = self.intake(x)\n",
    "        \n",
    "        i = -1\n",
    "        for i in range(self.n_layers-1):\n",
    "            hook = getattr(self, f'branched_layer_{i+1}')(hook)\n",
    "            hook = self.dropout( self.nonlin(hook) )\n",
    "        hook = getattr(self, f'branched_layer_{i+2}')(hook)\n",
    "            \n",
    "        return hook\n",
    "\n",
    "class RepeatLayer(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.repeat(*self.args)\n",
    "        \n",
    "class GroupedLinear(nn.Module):\n",
    "    def __init__(self, in_group_size, out_group_size, groups):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_group_size = in_group_size\n",
    "        self.out_group_size= out_group_size\n",
    "        self.groups        = groups\n",
    "        \n",
    "        #initialize weights\n",
    "        self.weight = torch.nn.Parameter(torch.zeros(groups, in_group_size, out_group_size))\n",
    "        self.bias   = torch.nn.Parameter(torch.zeros(groups, 1, out_group_size))\n",
    "        \n",
    "        #change weights to kaiming\n",
    "        self.reset_parameters(self.weight, self.bias)\n",
    "        \n",
    "    def reset_parameters(self, weights, bias):\n",
    "        torch.nn.init.kaiming_uniform_(weights, a=math.sqrt(3))\n",
    "        fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(weights)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        torch.nn.init.uniform_(bias, -bound, bound)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        reorg = x.permute(1,0).reshape(self.groups, self.in_group_size, -1).permute(0,2,1)\n",
    "        hook  = torch.bmm(reorg, self.weight) + self.bias\n",
    "        reorg = hook.permute(0,2,1).reshape(self.out_group_size*self.groups,-1).permute(1,0)\n",
    "        \n",
    "        return reorg\n",
    "class LinearNorm(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, \n",
    "                 batch_norm=True, weight_norm=True):\n",
    "        super(LinearNorm, self).__init__()\n",
    "        self.linear  = nn.Linear(in_features, out_features, bias=True)\n",
    "        if weight_norm:\n",
    "            self.linear = nn.utils.weight_norm(self.linear)\n",
    "        if batch_norm:\n",
    "            self.bn_layer = nn.BatchNorm1d(out_features, eps=1e-05, momentum=0.1, \n",
    "                                           affine=True, track_running_stats=True)\n",
    "    def forward(self, input):\n",
    "        try:\n",
    "            return self.bn_layer( self.linear( input ) )\n",
    "        except AttributeError:\n",
    "            return self.linear( input )\n",
    "class Conv1dNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 stride=1, padding=0, dilation=1, groups=1, \n",
    "                 bias=True, batch_norm=True, weight_norm=True):\n",
    "        super(Conv1dNorm, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, \n",
    "                              stride, padding, dilation, groups, bias)\n",
    "        if weight_norm:\n",
    "            self.conv = nn.utils.weight_norm(self.conv)\n",
    "        if batch_norm:\n",
    "            self.bn_layer = nn.BatchNorm1d(out_channels, eps=1e-05, momentum=0.1, \n",
    "                                           affine=True, track_running_stats=True)\n",
    "    def forward(self, input):\n",
    "        try:\n",
    "            return self.bn_layer( self.conv( input ) )\n",
    "        except AttributeError:\n",
    "            return self.conv( input )\n",
    "\n",
    "def get_padding(kernel_size):\n",
    "    \"\"\"\n",
    "    Calculate padding values for convolutional layers.\n",
    "\n",
    "    Args:\n",
    "        kernel_size (int): Size of the convolutional kernel.\n",
    "\n",
    "    Returns:\n",
    "        list: Padding values for left and right sides of the kernel.\n",
    "    \"\"\"\n",
    "    left = (kernel_size - 1) // 2\n",
    "    right= kernel_size - 1 - left\n",
    "    return [ max(0,x) for x in [left,right] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc474511-e82b-4055-a4cb-abea470acb61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BassetBranched(pl.LightningModule):\n",
    "    ######################\n",
    "    # Model construction #\n",
    "    ######################\n",
    "    \n",
    "    def __init__(self, input_len=600,\n",
    "                 conv1_channels=300, conv1_kernel_size=19, \n",
    "                 conv2_channels=200, conv2_kernel_size=11, \n",
    "                 conv3_channels=200, conv3_kernel_size=7, \n",
    "                 n_linear_layers=2, linear_channels=1000, \n",
    "                 linear_activation='ReLU', linear_dropout_p=0.3, \n",
    "                 n_branched_layers=1, branched_channels=250, \n",
    "                 branched_activation='ReLU6', branched_dropout_p=0., \n",
    "                 n_outputs=280,\n",
    "                 use_batch_norm=True, use_weight_norm=False, \n",
    "                 loss_criterion='L1KLmixed', loss_args={}):                                              \n",
    "        super().__init__()        \n",
    "        \n",
    "        self.input_len         = input_len\n",
    "        \n",
    "        self.conv1_channels    = conv1_channels\n",
    "        self.conv1_kernel_size = conv1_kernel_size\n",
    "        self.conv1_pad = get_padding(conv1_kernel_size)\n",
    "        \n",
    "        self.conv2_channels    = conv2_channels\n",
    "        self.conv2_kernel_size = conv2_kernel_size\n",
    "        self.conv2_pad = get_padding(conv2_kernel_size)\n",
    "\n",
    "        \n",
    "        self.conv3_channels    = conv3_channels\n",
    "        self.conv3_kernel_size = conv3_kernel_size\n",
    "        self.conv3_pad = get_padding(conv3_kernel_size)\n",
    "        \n",
    "        self.n_linear_layers   = n_linear_layers\n",
    "        self.linear_channels   = linear_channels\n",
    "        self.linear_activation = linear_activation\n",
    "        self.linear_dropout_p  = linear_dropout_p\n",
    "        \n",
    "        self.n_branched_layers = n_branched_layers\n",
    "        self.branched_channels = branched_channels\n",
    "        self.branched_activation = branched_activation\n",
    "        self.branched_dropout_p= branched_dropout_p\n",
    "        \n",
    "        self.n_outputs         = n_outputs\n",
    "        \n",
    "        self.loss_criterion    = loss_criterion\n",
    "        self.loss_args         = loss_args\n",
    "        \n",
    "        self.use_batch_norm    = use_batch_norm\n",
    "        self.use_weight_norm   = use_weight_norm\n",
    "        \n",
    "        self.pad1  = nn.ConstantPad1d(self.conv1_pad, 0.)\n",
    "        self.conv1 = Conv1dNorm(4, \n",
    "                                self.conv1_channels, self.conv1_kernel_size, \n",
    "                                stride=1, padding=0, dilation=1, groups=1, \n",
    "                                bias=True, \n",
    "                                batch_norm=self.use_batch_norm, \n",
    "                                weight_norm=self.use_weight_norm)\n",
    "        self.pad2  = nn.ConstantPad1d(self.conv2_pad, 0.)\n",
    "        self.conv2 = Conv1dNorm(self.conv1_channels, \n",
    "                                self.conv2_channels, self.conv2_kernel_size, \n",
    "                                stride=1, padding=0, dilation=1, groups=1, \n",
    "                                bias=True, \n",
    "                                batch_norm=self.use_batch_norm, \n",
    "                                weight_norm=self.use_weight_norm)\n",
    "        self.pad3  = nn.ConstantPad1d(self.conv3_pad, 0.)\n",
    "        self.conv3 = Conv1dNorm(self.conv2_channels, \n",
    "                                self.conv3_channels, self.conv3_kernel_size, \n",
    "                                stride=1, padding=0, dilation=1, groups=1, \n",
    "                                bias=True, \n",
    "                                batch_norm=self.use_batch_norm, \n",
    "                                weight_norm=self.use_weight_norm)\n",
    "        \n",
    "        self.pad4 = nn.ConstantPad1d((1,1), 0.)\n",
    "\n",
    "        self.maxpool_3 = nn.MaxPool1d(3, padding=0)\n",
    "        self.maxpool_4 = nn.MaxPool1d(4, padding=0)\n",
    "        \n",
    "        next_in_channels = self.conv3_channels * self.get_flatten_factor(self.input_len)\n",
    "        \n",
    "        for i in range(self.n_linear_layers):\n",
    "            \n",
    "            setattr(self, f'linear{i+1}', \n",
    "                    LinearNorm(next_in_channels, self.linear_channels, \n",
    "                               bias=True, \n",
    "                               batch_norm=self.use_batch_norm, \n",
    "                               weight_norm=self.use_weight_norm)\n",
    "                   )\n",
    "            next_in_channels = self.linear_channels\n",
    "\n",
    "        self.branched = BranchedLinear(next_in_channels, self.branched_channels, \n",
    "                                       self.branched_channels, \n",
    "                                       self.n_outputs, self.n_branched_layers, \n",
    "                                       self.branched_activation, self.branched_dropout_p)\n",
    "            \n",
    "        self.output  = GroupedLinear(self.branched_channels, 1, self.n_outputs)\n",
    "        \n",
    "        self.nonlin  = getattr(nn, self.linear_activation)()                               \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=self.linear_dropout_p)\n",
    "        \n",
    "        self.criterion = self.loss_criterion\n",
    "    \n",
    "    def get_flatten_factor(self, input_len):\n",
    "        \n",
    "        \n",
    "        \n",
    "        hook = input_len\n",
    "        assert hook % 3 == 0\n",
    "        hook = hook // 3\n",
    "        assert hook % 4 == 0\n",
    "        hook = hook // 4\n",
    "        assert (hook + 2) % 4 == 0\n",
    "        \n",
    "        return (hook + 2) // 4\n",
    "    \n",
    "    ######################\n",
    "    # Model computations #\n",
    "    ######################\n",
    "    \n",
    "    def encode(self, x):\n",
    "        hook = self.nonlin( self.conv1( self.pad1( x ) ) )\n",
    "        hook = self.maxpool_3( hook )\n",
    "        hook = self.nonlin( self.conv2( self.pad2( hook ) ) )\n",
    "        hook = self.maxpool_4( hook )\n",
    "        hook = self.nonlin( self.conv3( self.pad3( hook ) ) )\n",
    "        hook = self.maxpool_4( self.pad4( hook ) )        \n",
    "        hook = torch.flatten( hook, start_dim=1 )\n",
    "        return hook\n",
    "    \n",
    "    def decode(self, x):\n",
    "        hook = x\n",
    "        for i in range(self.n_linear_layers):\n",
    "            hook = self.dropout( \n",
    "                self.nonlin( \n",
    "                    getattr(self,f'linear{i+1}')(hook)\n",
    "                )\n",
    "            )\n",
    "        hook = self.branched(hook)\n",
    "\n",
    "        return hook\n",
    "    \n",
    "    def classify(self, x):\n",
    "        output = self.output( x )\n",
    "        return output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        output  = self.classify(decoded)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cafaaa82-c677-47d3-ae88-d1b410ea196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBasicTraining(pl.LightningModule):\n",
    "\n",
    "    ####################\n",
    "    # Standard methods #\n",
    "    ####################\n",
    "    \n",
    "    def __init__(self, model, optimizer='Adam', amsgrad = False,\n",
    "                          lr = 0.0032658700881052086,\n",
    "                          eps = 1e-08,\n",
    "                          weight_decay = 0.0003438210249762151,\n",
    "                          beta1 = 0.9,\n",
    "                          beta2 = 0.999, scheduler=None, \n",
    "                 scheduler_monitor=None, scheduler_interval='epoch', \n",
    "                 #optimizer_args=None, scheduler_args=None,\n",
    "                T_0=4096, T_mult=1, eta_min=0.0, last_epoch=-1):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = model.criterion\n",
    "        self.amsgrad = amsgrad\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.T_0 = T_0 \n",
    "        self.T_mult = T_mult\n",
    "        self.eta_min = eta_min\n",
    "        self.last_epoch = last_epoch\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.scheduler_monitor = scheduler_monitor\n",
    "        self.scheduler_interval= scheduler_interval\n",
    "        #self.optimizer_args = optimizer_args\n",
    "        #self.scheduler_args = scheduler_args\n",
    "\n",
    "        # 1. Create a list to hold the outputs of `*_step`\n",
    "        self.arit_means = []\n",
    "        self.harm_means = []\n",
    "        self.epoch_pred = []\n",
    "        self.epoch_label = []\n",
    "        self.pearsons = []\n",
    "        \n",
    "    def forward(self, input):\n",
    "\n",
    "        return self.model(input)\n",
    "\n",
    "    ###################\n",
    "    # Non-PTL methods #\n",
    "    ###################\n",
    "        \n",
    "    def categorical_mse(self, x, y):\n",
    "        return (x - y).pow(2).mean(dim=0)\n",
    "        \n",
    "    def aug_log(self, internal_metrics=None, external_metrics=None):\n",
    "        if internal_metrics is not None:\n",
    "            for my_key, my_value in internal_metrics.items():\n",
    "                self.log(my_key, my_value)\n",
    "                '''\n",
    "                self.hpt.report_hyperparameter_tuning_metric(\n",
    "                    hyperparameter_metric_tag=my_key,\n",
    "                    metric_value=my_value,\n",
    "                    global_step=self.global_step)\n",
    "                    '''\n",
    "                \n",
    "        if external_metrics is not None:\n",
    "            res_str = '|'\n",
    "            for my_key, my_value in external_metrics.items():\n",
    "                self.log(my_key, my_value)\n",
    "                res_str += ' {}: {:.5f} |'.format(my_key, my_value)\n",
    "                '''\n",
    "                self.hpt.report_hyperparameter_tuning_metric(\n",
    "                    hyperparameter_metric_tag=my_key,\n",
    "                    metric_value=my_value,\n",
    "                    global_step=self.global_step)\n",
    "                    '''\n",
    "            border = '-'*len(res_str)\n",
    "            print(\"\\n\".join(['',border, res_str, border,'']))\n",
    "        \n",
    "        return None\n",
    "\n",
    "    #############\n",
    "    # PTL hooks #\n",
    "    #############\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        #self.hpt = hypertune.HyperTune()\n",
    "        params = [ x for x in self.parameters() if x.requires_grad ]\n",
    "        print(f'Found {sum(p.numel() for p in params)} parameters')\n",
    "        optim_class = getattr(torch.optim,self.optimizer)\n",
    "        my_optimizer= optim_class(self.parameters(), lr=self.lr, \n",
    "                                  weight_decay=self.weight_decay, \n",
    "                                  betas=(self.beta1, self.beta2), \n",
    "                                  eps = self.eps,\n",
    "                                  amsgrad=self.amsgrad) \n",
    "        if self.scheduler is not None:\n",
    "            sch_dict = {\n",
    "                'scheduler': getattr(torch.optim.lr_scheduler,\n",
    "                                     self.scheduler)(my_optimizer, \n",
    "                                                     max_lr = self.lr,\n",
    "                                                     three_phase=False, \n",
    "                                                     total_steps=self.trainer.estimated_stepping_batches,\n",
    "                                                        pct_start=0.3,\n",
    "                                                        cycle_momentum = False), \n",
    "                                                     '''\n",
    "                                                     T_0=self.T_0, \n",
    "                                                     T_mult=self.T_mult, \n",
    "                                                     eta_min=self.eta_min,\n",
    "                                                     last_epoch = self.last_epoch\n",
    "                                                     '''\n",
    "                                                    \n",
    "                'interval': self.scheduler_interval, \n",
    "                'name': 'learning_rate'\n",
    "            }\n",
    "            if self.scheduler_monitor is not None:\n",
    "                sch_dict['monitor'] = self.scheduler_monitor\n",
    "            return [my_optimizer], [sch_dict]\n",
    "        else:\n",
    "            return my_optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y   = batch\n",
    "        y_hat  = self(x)\n",
    "        loss   = self.criterion(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "       \n",
    "        x, y   = batch\n",
    "        y_hat = self(x)\n",
    "        loss   = self.criterion(y_hat, y)\n",
    "        self.log('valid_loss', loss)\n",
    "        metric = self.categorical_mse(y_hat, y)\n",
    "        \n",
    "        # 2. Add the outputs to the list\n",
    "        self.arit_means.append(loss)\n",
    "        self.harm_means.append(metric)\n",
    "        self.epoch_pred.append(y_hat)\n",
    "        self.epoch_label.append(y)\n",
    "        \n",
    "        return {'loss': loss, 'metric': metric, 'preds': y_hat, 'labels': y}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        '''\n",
    "        arit_mean = torch.stack([ batch['loss'] for batch in val_step_outputs ], dim=0).mean()\n",
    "        harm_mean = torch.stack([ batch['metric'] for batch in val_step_outputs ], dim=0).mean(dim=0).pow(-1).mean().pow(-1)\n",
    "        epoch_preds = torch.cat([batch['preds'] for batch in val_step_outputs], dim=0)\n",
    "        epoch_labels  = torch.cat([batch['labels'] for batch in val_step_outputs], dim=0)\n",
    "        '''\n",
    "        # 3. Do something with all outputs\n",
    "        arit_mean = torch.stack( self.arit_means, dim=0).mean()\n",
    "        harm_mean = torch.stack(self.harm_means, dim=0).mean(dim=0).pow(-1).mean().pow(-1)\n",
    "        epoch_preds = torch.cat(self.epoch_pred, dim=0)\n",
    "        epoch_labels  = torch.cat(self.epoch_label, dim=0)\n",
    "        pearson, mean_pearson = pearson_correlation(epoch_preds, epoch_labels)\n",
    "        spearman, mean_spearman = spearman_correlation(epoch_preds, epoch_labels)\n",
    "        shannon_pred, shannon_label = shannon_entropy(epoch_preds), shannon_entropy(epoch_labels)\n",
    "        specificity_spearman, specificity_mean_spearman = spearman_correlation(shannon_pred, shannon_label)\n",
    "        self.aug_log(external_metrics={\n",
    "            'current_epoch': self.current_epoch, \n",
    "            'arithmetic_mean_loss': arit_mean,\n",
    "            'harmonic_mean_loss': harm_mean,\n",
    "            'prediction_mean_pearson': mean_pearson.item(),\n",
    "            'prediction_mean_spearman': mean_spearman.item(),\n",
    "            'entropy_spearman': specificity_mean_spearman.item()\n",
    "        })\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "       \n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log('test_loss', loss)  \n",
    "        pearson, mean_pearson = pearson_correlation(y_pred, y)\n",
    "        self.log(\"test_pearson\", mean_pearson)\n",
    "        \n",
    "class CNNTransferLearning(CNNBasicTraining):\n",
    "    \n",
    "    ####################\n",
    "    # Standard methods #\n",
    "    ####################\n",
    "    \n",
    "    def __init__(self, model, parent_weights, frozen_epochs=0, \n",
    "                 optimizer='Adam', amsgrad = True,\n",
    "                          lr = 0.0032658700881052086,\n",
    "                          eps = 1e-08,\n",
    "                          weight_decay = 0.0003438210249762151,\n",
    "                          beta1 = 0.8661062881299633,\n",
    "                          beta2 = 0.879223105336538, scheduler=None, \n",
    "                 scheduler_monitor=None, scheduler_interval='epoch', \n",
    "                 #optimizer_args=None, scheduler_args=None\n",
    "                T_0=4096, T_mult=1, eta_min=0.0, last_epoch=-1):\n",
    "        \n",
    "        super().__init__(model, optimizer, amsgrad, lr, eps, weight_decay, beta1, beta2,\n",
    "                         scheduler, scheduler_monitor, \n",
    "                         scheduler_interval, \n",
    "                         #optimizer_args, scheduler_args,\n",
    "                         T_0, T_mult, eta_min, last_epoch)\n",
    "        \n",
    "        self.parent_weights = parent_weights\n",
    "        self.frozen_epochs  = frozen_epochs\n",
    "        \n",
    "    ###################\n",
    "    # Non-PTL methods #\n",
    "    ###################\n",
    "        '''\n",
    "    def attach_parent_weights(self, my_weights):\n",
    "\n",
    "        parent_state_dict = torch.load(my_weights)\n",
    "        if 'model_state_dict' in parent_state_dict.keys():\n",
    "            parent_state_dict = parent_state_dict['model_state_dict']\n",
    "            \n",
    "        mod_state_dict = filter_state_dict(self.model, parent_state_dict)\n",
    "        self.model.load_state_dict( mod_state_dict['filtered_state_dict'], strict=False )\n",
    "        return mod_state_dict['passed_keys']\n",
    "    \n",
    "    #############\n",
    "    # PTL hooks #\n",
    "    #############\n",
    "        \n",
    "    def setup(self, stage='training'):\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "            if 'tar.gz' in self.parent_weights:\n",
    "                utils.unpack_artifact(self.parent_weights, tmpdirname)\n",
    "                old_model = utils.model_fn(os.path.join( tmpdirname, 'artifacts' ))\n",
    "                the_weights = os.path.join( tmpdirname, 'stash_dict.pkl' )\n",
    "                torch.save(old_model.state_dict(), the_weights)\n",
    "            elif 'gs://' in self.parent_weights:\n",
    "                subprocess.call(['gsutil','cp',self.parent_weights,tmpdirname])\n",
    "                the_weights = os.path.join( tmpdirname, os.path.basename(self.parent_weights) )\n",
    "            else:\n",
    "                the_weights = self.parent_weights\n",
    "            self.transferred_keys = self.attach_parent_weights(the_weights)\n",
    "        \n",
    "    def on_train_epoch_start(self):\n",
    "        print(f'starting epoch {self.current_epoch}')\n",
    "        for name, p in self.named_parameters():\n",
    "            if self.current_epoch < self.frozen_epochs:\n",
    "                if name in self.transferred_keys:\n",
    "                    p.requires_grad = False\n",
    "                else:\n",
    "                    p.requires_grad = True\n",
    "            else:\n",
    "                p.requires_grad = True\n",
    "                '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af27ddc-ea9c-4105-9b2e-0965a533594c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# without t.Reverse(0.5), but with reverse augs, origin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c3ed9c5-47a1-4fba-a100-a3618658c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "train_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    #t.Reverse(0.5),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "val_test_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "\n",
    "target_transform = t_t.Compose([\n",
    "    t_t.Normalize(mean = 0.500, std = 1.059) # original for Malinois \n",
    "])\n",
    "activity_columns = ['HepG2','SKNSH', \"K562\"]\n",
    "#stderr = ['lfcSE_k562', 'lfcSE_hepg2', 'lfcSE_sknsh']\n",
    "stderr = ['K562_lfcSE', 'HepG2_lfcSE', 'SKNSH_lfcSE']\n",
    "#seq = \"nt_sequence\"\n",
    "seq = \"sequence\"\n",
    "# load the data\n",
    "train_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, \"Y\"], \n",
    "                                split = \"train\",\n",
    "                              filtration = \"original\",\n",
    "                                duplication_cutoff = 0.5,\n",
    "                                use_reverse_complement = True,\n",
    "                                stderr_columns = stderr,\n",
    "                                sequence_column = seq,\n",
    "                              transform = train_transform,\n",
    "                               target_transform = target_transform) \n",
    "\n",
    "val_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [7, 13], \n",
    "                              split = \"val\",\n",
    "                              filtration = \"original\",\n",
    "                              sequence_column = seq,\n",
    "                              stderr_columns = stderr,\n",
    "                              transform = val_test_transform,\n",
    "                             target_transform = target_transform) \n",
    "\n",
    "test_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [9, 21, \"X\"],\n",
    "                               split = \"test\",\n",
    "                              filtration = \"original\",\n",
    "                               sequence_column = seq,\n",
    "                               stderr_columns = stderr,\n",
    "                              transform = val_test_transform,\n",
    "                              target_transform = target_transform)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = NUM_WORKERS)\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee079a1b-108d-4e31-9ce4-8ac4dc1e6992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MalinoisDataset of size 1864208 (MpraDaraset)\n",
      "    Number of datapoints: 1864208\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['1', '2', '3', '4', '5', '6', '8', '9', '10', '11', '12', '14', '15', '16', '17', '18', '20', '22', 'Y']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_log2FC', 'SKNSH_log2FC', 'K562_log2FC']\n",
      "    Target columns that can be used: {'K562_log2FC', 'HepG2_log2FC', 'SKNSH_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 58810 (MpraDaraset)\n",
      "    Number of datapoints: 58810\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['19', '21', 'X']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_log2FC', 'SKNSH_log2FC', 'K562_log2FC']\n",
      "    Target columns that can be used: {'K562_log2FC', 'HepG2_log2FC', 'SKNSH_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 62582 (MpraDaraset)\n",
      "    Number of datapoints: 62582\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['7', '13']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_log2FC', 'SKNSH_log2FC', 'K562_log2FC']\n",
      "    Target columns that can be used: {'K562_log2FC', 'HepG2_log2FC', 'SKNSH_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(\"=\"*50)\n",
    "print(val_dataset)\n",
    "print(\"=\"*50)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a565107-f68f-4d27-9257-2d5c0387dc0f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type           | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model     | BassetBranched | 4.1 M  | train\n",
      "1 | criterion | L1KLmixed      | 0      | train\n",
      "-----------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.429    Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4107183 parameters\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.14111 | harmonic_mean_loss: 1.28775 | prediction_mean_pearson: -0.00475 | prediction_mean_spearman: -0.02725 | entropy_spearman: 0.07296 |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.12353 | harmonic_mean_loss: 0.81533 | prediction_mean_pearson: 0.73623 | prediction_mean_spearman: 0.64304 | entropy_spearman: 0.25231 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 1.00000 | arithmetic_mean_loss: 0.11188 | harmonic_mean_loss: 0.71121 | prediction_mean_pearson: 0.76261 | prediction_mean_spearman: 0.64578 | entropy_spearman: 0.33361 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 2.00000 | arithmetic_mean_loss: 0.10932 | harmonic_mean_loss: 0.69522 | prediction_mean_pearson: 0.76561 | prediction_mean_spearman: 0.64265 | entropy_spearman: 0.34369 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 3.00000 | arithmetic_mean_loss: 0.10674 | harmonic_mean_loss: 0.67816 | prediction_mean_pearson: 0.77528 | prediction_mean_spearman: 0.64859 | entropy_spearman: 0.36802 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 4.00000 | arithmetic_mean_loss: 0.10626 | harmonic_mean_loss: 0.66126 | prediction_mean_pearson: 0.78112 | prediction_mean_spearman: 0.65569 | entropy_spearman: 0.37322 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 5.00000 | arithmetic_mean_loss: 0.10495 | harmonic_mean_loss: 0.63982 | prediction_mean_pearson: 0.78871 | prediction_mean_spearman: 0.66507 | entropy_spearman: 0.38212 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 6.00000 | arithmetic_mean_loss: 0.10312 | harmonic_mean_loss: 0.61853 | prediction_mean_pearson: 0.79581 | prediction_mean_spearman: 0.67531 | entropy_spearman: 0.39379 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 7.00000 | arithmetic_mean_loss: 0.10301 | harmonic_mean_loss: 0.61392 | prediction_mean_pearson: 0.79747 | prediction_mean_spearman: 0.67638 | entropy_spearman: 0.39064 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 8.00000 | arithmetic_mean_loss: 0.10167 | harmonic_mean_loss: 0.59860 | prediction_mean_pearson: 0.80288 | prediction_mean_spearman: 0.68382 | entropy_spearman: 0.40014 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 9.00000 | arithmetic_mean_loss: 0.10192 | harmonic_mean_loss: 0.59384 | prediction_mean_pearson: 0.80347 | prediction_mean_spearman: 0.68283 | entropy_spearman: 0.40065 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 10.00000 | arithmetic_mean_loss: 0.10147 | harmonic_mean_loss: 0.58500 | prediction_mean_pearson: 0.80640 | prediction_mean_spearman: 0.68658 | entropy_spearman: 0.40357 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 11.00000 | arithmetic_mean_loss: 0.10125 | harmonic_mean_loss: 0.58481 | prediction_mean_pearson: 0.80677 | prediction_mean_spearman: 0.68538 | entropy_spearman: 0.40494 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 12.00000 | arithmetic_mean_loss: 0.10089 | harmonic_mean_loss: 0.58342 | prediction_mean_pearson: 0.80773 | prediction_mean_spearman: 0.68612 | entropy_spearman: 0.40753 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 13.00000 | arithmetic_mean_loss: 0.10014 | harmonic_mean_loss: 0.57553 | prediction_mean_pearson: 0.81049 | prediction_mean_spearman: 0.69041 | entropy_spearman: 0.41318 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 14.00000 | arithmetic_mean_loss: 0.10009 | harmonic_mean_loss: 0.57297 | prediction_mean_pearson: 0.81127 | prediction_mean_spearman: 0.69109 | entropy_spearman: 0.41065 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 15.00000 | arithmetic_mean_loss: 0.09963 | harmonic_mean_loss: 0.56822 | prediction_mean_pearson: 0.81317 | prediction_mean_spearman: 0.69390 | entropy_spearman: 0.41459 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 16.00000 | arithmetic_mean_loss: 0.09945 | harmonic_mean_loss: 0.56629 | prediction_mean_pearson: 0.81386 | prediction_mean_spearman: 0.69490 | entropy_spearman: 0.41543 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 17.00000 | arithmetic_mean_loss: 0.09911 | harmonic_mean_loss: 0.56225 | prediction_mean_pearson: 0.81509 | prediction_mean_spearman: 0.69715 | entropy_spearman: 0.41833 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 18.00000 | arithmetic_mean_loss: 0.09950 | harmonic_mean_loss: 0.57011 | prediction_mean_pearson: 0.81269 | prediction_mean_spearman: 0.68989 | entropy_spearman: 0.41687 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 19.00000 | arithmetic_mean_loss: 0.09927 | harmonic_mean_loss: 0.56793 | prediction_mean_pearson: 0.81370 | prediction_mean_spearman: 0.69104 | entropy_spearman: 0.41815 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 20.00000 | arithmetic_mean_loss: 0.09884 | harmonic_mean_loss: 0.56317 | prediction_mean_pearson: 0.81535 | prediction_mean_spearman: 0.69365 | entropy_spearman: 0.42087 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 21.00000 | arithmetic_mean_loss: 0.09882 | harmonic_mean_loss: 0.56263 | prediction_mean_pearson: 0.81558 | prediction_mean_spearman: 0.69389 | entropy_spearman: 0.42074 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 22.00000 | arithmetic_mean_loss: 0.09852 | harmonic_mean_loss: 0.55927 | prediction_mean_pearson: 0.81687 | prediction_mean_spearman: 0.69585 | entropy_spearman: 0.42281 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 23.00000 | arithmetic_mean_loss: 0.09874 | harmonic_mean_loss: 0.56132 | prediction_mean_pearson: 0.81649 | prediction_mean_spearman: 0.69547 | entropy_spearman: 0.42072 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 24.00000 | arithmetic_mean_loss: 0.09854 | harmonic_mean_loss: 0.55990 | prediction_mean_pearson: 0.81726 | prediction_mean_spearman: 0.69684 | entropy_spearman: 0.42178 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 25.00000 | arithmetic_mean_loss: 0.09844 | harmonic_mean_loss: 0.55978 | prediction_mean_pearson: 0.81763 | prediction_mean_spearman: 0.69730 | entropy_spearman: 0.42278 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 26.00000 | arithmetic_mean_loss: 0.09833 | harmonic_mean_loss: 0.55823 | prediction_mean_pearson: 0.81817 | prediction_mean_spearman: 0.69832 | entropy_spearman: 0.42330 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 27.00000 | arithmetic_mean_loss: 0.09802 | harmonic_mean_loss: 0.55475 | prediction_mean_pearson: 0.81924 | prediction_mean_spearman: 0.70005 | entropy_spearman: 0.42518 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 28.00000 | arithmetic_mean_loss: 0.09819 | harmonic_mean_loss: 0.55403 | prediction_mean_pearson: 0.81906 | prediction_mean_spearman: 0.69939 | entropy_spearman: 0.42461 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 29.00000 | arithmetic_mean_loss: 0.09797 | harmonic_mean_loss: 0.55137 | prediction_mean_pearson: 0.81986 | prediction_mean_spearman: 0.70084 | entropy_spearman: 0.42571 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 30.00000 | arithmetic_mean_loss: 0.09806 | harmonic_mean_loss: 0.55296 | prediction_mean_pearson: 0.81958 | prediction_mean_spearman: 0.70102 | entropy_spearman: 0.42547 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but the required `min_epochs=60` or `min_steps=None` has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 31.00000 | arithmetic_mean_loss: 0.09814 | harmonic_mean_loss: 0.55455 | prediction_mean_pearson: 0.81927 | prediction_mean_spearman: 0.70069 | entropy_spearman: 0.42537 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 32.00000 | arithmetic_mean_loss: 0.09789 | harmonic_mean_loss: 0.55180 | prediction_mean_pearson: 0.82016 | prediction_mean_spearman: 0.70218 | entropy_spearman: 0.42703 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 33.00000 | arithmetic_mean_loss: 0.09788 | harmonic_mean_loss: 0.55158 | prediction_mean_pearson: 0.82031 | prediction_mean_spearman: 0.70233 | entropy_spearman: 0.42724 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 34.00000 | arithmetic_mean_loss: 0.09766 | harmonic_mean_loss: 0.54951 | prediction_mean_pearson: 0.82103 | prediction_mean_spearman: 0.70347 | entropy_spearman: 0.42869 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 35.00000 | arithmetic_mean_loss: 0.09779 | harmonic_mean_loss: 0.55060 | prediction_mean_pearson: 0.82072 | prediction_mean_spearman: 0.70298 | entropy_spearman: 0.42819 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 36.00000 | arithmetic_mean_loss: 0.09764 | harmonic_mean_loss: 0.54887 | prediction_mean_pearson: 0.82126 | prediction_mean_spearman: 0.70382 | entropy_spearman: 0.42901 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 37.00000 | arithmetic_mean_loss: 0.09842 | harmonic_mean_loss: 0.55366 | prediction_mean_pearson: 0.81833 | prediction_mean_spearman: 0.69918 | entropy_spearman: 0.42728 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 38.00000 | arithmetic_mean_loss: 0.09840 | harmonic_mean_loss: 0.55266 | prediction_mean_pearson: 0.81863 | prediction_mean_spearman: 0.69989 | entropy_spearman: 0.42738 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 39.00000 | arithmetic_mean_loss: 0.09818 | harmonic_mean_loss: 0.55044 | prediction_mean_pearson: 0.81937 | prediction_mean_spearman: 0.70115 | entropy_spearman: 0.42882 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 40.00000 | arithmetic_mean_loss: 0.09826 | harmonic_mean_loss: 0.55007 | prediction_mean_pearson: 0.81915 | prediction_mean_spearman: 0.70132 | entropy_spearman: 0.42876 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 41.00000 | arithmetic_mean_loss: 0.09810 | harmonic_mean_loss: 0.54833 | prediction_mean_pearson: 0.81979 | prediction_mean_spearman: 0.70235 | entropy_spearman: 0.42992 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 42.00000 | arithmetic_mean_loss: 0.09822 | harmonic_mean_loss: 0.54847 | prediction_mean_pearson: 0.81937 | prediction_mean_spearman: 0.70223 | entropy_spearman: 0.42960 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 43.00000 | arithmetic_mean_loss: 0.09811 | harmonic_mean_loss: 0.54708 | prediction_mean_pearson: 0.81968 | prediction_mean_spearman: 0.70294 | entropy_spearman: 0.43024 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 44.00000 | arithmetic_mean_loss: 0.09825 | harmonic_mean_loss: 0.54740 | prediction_mean_pearson: 0.81929 | prediction_mean_spearman: 0.70245 | entropy_spearman: 0.42826 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 45.00000 | arithmetic_mean_loss: 0.09823 | harmonic_mean_loss: 0.54655 | prediction_mean_pearson: 0.81948 | prediction_mean_spearman: 0.70257 | entropy_spearman: 0.42836 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 46.00000 | arithmetic_mean_loss: 0.09806 | harmonic_mean_loss: 0.54483 | prediction_mean_pearson: 0.82010 | prediction_mean_spearman: 0.70352 | entropy_spearman: 0.42936 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 47.00000 | arithmetic_mean_loss: 0.09799 | harmonic_mean_loss: 0.54419 | prediction_mean_pearson: 0.82042 | prediction_mean_spearman: 0.70412 | entropy_spearman: 0.42978 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 48.00000 | arithmetic_mean_loss: 0.09789 | harmonic_mean_loss: 0.54276 | prediction_mean_pearson: 0.82089 | prediction_mean_spearman: 0.70477 | entropy_spearman: 0.43052 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 49.00000 | arithmetic_mean_loss: 0.09837 | harmonic_mean_loss: 0.54572 | prediction_mean_pearson: 0.81943 | prediction_mean_spearman: 0.70216 | entropy_spearman: 0.42924 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 50.00000 | arithmetic_mean_loss: 0.09825 | harmonic_mean_loss: 0.54444 | prediction_mean_pearson: 0.81993 | prediction_mean_spearman: 0.70291 | entropy_spearman: 0.42970 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 51.00000 | arithmetic_mean_loss: 0.09818 | harmonic_mean_loss: 0.54396 | prediction_mean_pearson: 0.82009 | prediction_mean_spearman: 0.70340 | entropy_spearman: 0.42985 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 52.00000 | arithmetic_mean_loss: 0.09824 | harmonic_mean_loss: 0.54389 | prediction_mean_pearson: 0.82018 | prediction_mean_spearman: 0.70341 | entropy_spearman: 0.42981 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 53.00000 | arithmetic_mean_loss: 0.09810 | harmonic_mean_loss: 0.54258 | prediction_mean_pearson: 0.82069 | prediction_mean_spearman: 0.70424 | entropy_spearman: 0.43075 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 54.00000 | arithmetic_mean_loss: 0.09810 | harmonic_mean_loss: 0.54324 | prediction_mean_pearson: 0.82056 | prediction_mean_spearman: 0.70426 | entropy_spearman: 0.43077 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 55.00000 | arithmetic_mean_loss: 0.09798 | harmonic_mean_loss: 0.54236 | prediction_mean_pearson: 0.82094 | prediction_mean_spearman: 0.70484 | entropy_spearman: 0.43106 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 56.00000 | arithmetic_mean_loss: 0.09799 | harmonic_mean_loss: 0.54346 | prediction_mean_pearson: 0.82058 | prediction_mean_spearman: 0.70411 | entropy_spearman: 0.43086 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 57.00000 | arithmetic_mean_loss: 0.09790 | harmonic_mean_loss: 0.54281 | prediction_mean_pearson: 0.82081 | prediction_mean_spearman: 0.70448 | entropy_spearman: 0.43124 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 58.00000 | arithmetic_mean_loss: 0.09776 | harmonic_mean_loss: 0.54144 | prediction_mean_pearson: 0.82132 | prediction_mean_spearman: 0.70525 | entropy_spearman: 0.43213 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 59.00000 | arithmetic_mean_loss: 0.09774 | harmonic_mean_loss: 0.54115 | prediction_mean_pearson: 0.82147 | prediction_mean_spearman: 0.70541 | entropy_spearman: 0.43209 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.08871891349554062\n",
      "      test_pearson          0.7482768297195435\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.08871891349554062, 'test_pearson': 0.7482768297195435}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BassetBranched(linear_dropout_p=0.11625456877954289,\n",
    "                      branched_activation='ReLU', branched_channels=140,\n",
    "                      branched_dropout_p=0.5757068086404574, \n",
    "                       n_outputs=len(train_dataset[0][1]),\n",
    "                      n_linear_layers=1, n_branched_layers=3, use_batch_norm=True,\n",
    "                      loss_criterion=L1KLmixed(beta=5.0, reduction='mean'))\n",
    "seq_model = CNNTransferLearning(model = model,\n",
    "    parent_weights = \"gs://tewhey-public-data/CODA_resources/my-model.epoch_5-step_19885.pkl\",\n",
    "                       frozen_epochs = 0,\n",
    "                          optimizer = \"Adam\",\n",
    "                          scheduler=\"CosineAnnealingWarmRestarts\",\n",
    "                          scheduler_interval=\"step\")\n",
    "\n",
    "callback_topmodel = pl.callbacks.ModelCheckpoint(monitor=\"prediction_mean_pearson\",\n",
    "                                                 save_top_k=1,\n",
    "                                                 dirpath=\"./Malinois\",\n",
    "                                                 filename=\"Malinois_max\")\n",
    "callback_es = pl.callbacks.early_stopping.EarlyStopping(monitor='prediction_mean_pearson', \n",
    "                                                        patience=30)\n",
    "\n",
    "logger = pl_loggers.TensorBoardLogger(\"./logs_Malinois\", name = \"Malinois_example\")\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu', \n",
    "    devices=[0], \n",
    "    min_epochs=60, \n",
    "    max_epochs=200,\n",
    "    precision=16,\n",
    "    enable_progress_bar = False,\n",
    "    callbacks=[\n",
    "        #TQDMProgressBar(refresh_rate=50), \n",
    "        callback_es, \n",
    "        #callback_topmodel\n",
    "    ],\n",
    "    logger = logger\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(seq_model,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)\n",
    "trainer.test(seq_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc8647-b7ae-4c5d-a88a-92b1afcbcb1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Use MPRA_ALL_HD_v2 with use_reverse_complement = True and without t.Reverse(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc1a8f6-d20c-48c5-9d09-43e899af59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "train_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    #t.Reverse(0.5),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "val_test_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "\n",
    "target_transform = t_t.Compose([\n",
    "    t_t.Normalize(mean = 0.500, std = 1.059) # original for Malinois \n",
    "])\n",
    "activity_columns = ['HepG2','SKNSH', \"K562\"]\n",
    "stderr = ['lfcSE_k562', 'lfcSE_hepg2', 'lfcSE_sknsh']\n",
    "#stderr = ['K562_lfcSE', 'HepG2_lfcSE', 'SKNSH_lfcSE']\n",
    "seq = \"nt_sequence\"\n",
    "#seq = \"sequence\"\n",
    "# load the data\n",
    "train_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, \"Y\"], \n",
    "                                split = \"train\",\n",
    "                              filtration = \"original\",\n",
    "                                duplication_cutoff = 0.5,\n",
    "                                use_reverse_complement = True,\n",
    "                                stderr_columns = stderr,\n",
    "                                sequence_column = seq,\n",
    "                              transform = train_transform,\n",
    "                               target_transform = target_transform) \n",
    "\n",
    "val_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [7, 13], \n",
    "                              split = \"val\",\n",
    "                              filtration = \"original\",\n",
    "                              sequence_column = seq,\n",
    "                              stderr_columns = stderr,\n",
    "                              transform = val_test_transform,\n",
    "                             target_transform = target_transform) \n",
    "\n",
    "test_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [9, 21, \"X\"],\n",
    "                               split = \"test\",\n",
    "                              filtration = \"original\",\n",
    "                               sequence_column = seq,\n",
    "                               stderr_columns = stderr,\n",
    "                              transform = val_test_transform,\n",
    "                              target_transform = target_transform)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = NUM_WORKERS)\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6a572cb-964c-426e-9c7b-62b7e2f31148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MalinoisDataset of size 1666532 (MpraDaraset)\n",
      "    Number of datapoints: 1666532\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['1', '2', '3', '4', '5', '6', '8', '9', '10', '11', '12', '14', '15', '16', '17', '18', '20', '22', 'Y']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_mean', 'SKNSH_mean', 'K562_mean']\n",
      "    Target columns that can be used: {'HepG2_log2FC', 'K562_log2FC', 'SKNSH_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 51991 (MpraDaraset)\n",
      "    Number of datapoints: 51991\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['19', '21', 'X']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_mean', 'SKNSH_mean', 'K562_mean']\n",
      "    Target columns that can be used: {'HepG2_log2FC', 'K562_log2FC', 'SKNSH_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 55841 (MpraDaraset)\n",
      "    Number of datapoints: 55841\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['7', '13']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_mean', 'SKNSH_mean', 'K562_mean']\n",
      "    Target columns that can be used: {'HepG2_log2FC', 'K562_log2FC', 'SKNSH_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(\"=\"*50)\n",
    "print(val_dataset)\n",
    "print(\"=\"*50)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7f9d260-7319-41ba-aa04-04512d4d4a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nios/miniconda3/envs/mpra/lib/python3.12/site-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type           | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model     | BassetBranched | 4.1 M  | train\n",
      "1 | criterion | L1KLmixed      | 0      | train\n",
      "-----------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.429    Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4107183 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nios/miniconda3/envs/mpra/lib/python3.12/site-packages/torch/nn/functional.py:2994: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.13618 | harmonic_mean_loss: 1.21210 | prediction_mean_pearson: -0.01456 | prediction_mean_spearman: -0.00196 | entropy_spearman: -0.01279 |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.12098 | harmonic_mean_loss: 0.81087 | prediction_mean_pearson: 0.72466 | prediction_mean_spearman: 0.61541 | entropy_spearman: 0.21917 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 1.00000 | arithmetic_mean_loss: 0.11128 | harmonic_mean_loss: 0.73346 | prediction_mean_pearson: 0.74910 | prediction_mean_spearman: 0.63246 | entropy_spearman: 0.32050 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 2.00000 | arithmetic_mean_loss: 0.10850 | harmonic_mean_loss: 0.70703 | prediction_mean_pearson: 0.75574 | prediction_mean_spearman: 0.64533 | entropy_spearman: 0.34510 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 3.00000 | arithmetic_mean_loss: 0.10649 | harmonic_mean_loss: 0.68351 | prediction_mean_pearson: 0.76623 | prediction_mean_spearman: 0.65488 | entropy_spearman: 0.35415 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 4.00000 | arithmetic_mean_loss: 0.10394 | harmonic_mean_loss: 0.65462 | prediction_mean_pearson: 0.77748 | prediction_mean_spearman: 0.67072 | entropy_spearman: 0.37602 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 5.00000 | arithmetic_mean_loss: 0.10397 | harmonic_mean_loss: 0.66244 | prediction_mean_pearson: 0.77748 | prediction_mean_spearman: 0.66973 | entropy_spearman: 0.38388 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 6.00000 | arithmetic_mean_loss: 0.10241 | harmonic_mean_loss: 0.64103 | prediction_mean_pearson: 0.78510 | prediction_mean_spearman: 0.67883 | entropy_spearman: 0.39372 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 7.00000 | arithmetic_mean_loss: 0.10362 | harmonic_mean_loss: 0.63959 | prediction_mean_pearson: 0.78523 | prediction_mean_spearman: 0.67567 | entropy_spearman: 0.36738 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 8.00000 | arithmetic_mean_loss: 0.10285 | harmonic_mean_loss: 0.63083 | prediction_mean_pearson: 0.78888 | prediction_mean_spearman: 0.67974 | entropy_spearman: 0.37650 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 9.00000 | arithmetic_mean_loss: 0.10171 | harmonic_mean_loss: 0.61652 | prediction_mean_pearson: 0.79375 | prediction_mean_spearman: 0.68591 | entropy_spearman: 0.38652 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 10.00000 | arithmetic_mean_loss: 0.10151 | harmonic_mean_loss: 0.60997 | prediction_mean_pearson: 0.79459 | prediction_mean_spearman: 0.68746 | entropy_spearman: 0.39088 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 11.00000 | arithmetic_mean_loss: 0.10113 | harmonic_mean_loss: 0.60099 | prediction_mean_pearson: 0.79705 | prediction_mean_spearman: 0.68927 | entropy_spearman: 0.39559 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 12.00000 | arithmetic_mean_loss: 0.10024 | harmonic_mean_loss: 0.59092 | prediction_mean_pearson: 0.80085 | prediction_mean_spearman: 0.69397 | entropy_spearman: 0.40272 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 13.00000 | arithmetic_mean_loss: 0.09989 | harmonic_mean_loss: 0.58577 | prediction_mean_pearson: 0.80246 | prediction_mean_spearman: 0.69575 | entropy_spearman: 0.40464 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 14.00000 | arithmetic_mean_loss: 0.09954 | harmonic_mean_loss: 0.58018 | prediction_mean_pearson: 0.80451 | prediction_mean_spearman: 0.69765 | entropy_spearman: 0.40651 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 15.00000 | arithmetic_mean_loss: 0.09949 | harmonic_mean_loss: 0.57889 | prediction_mean_pearson: 0.80481 | prediction_mean_spearman: 0.69646 | entropy_spearman: 0.40779 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 16.00000 | arithmetic_mean_loss: 0.09936 | harmonic_mean_loss: 0.57830 | prediction_mean_pearson: 0.80534 | prediction_mean_spearman: 0.69572 | entropy_spearman: 0.40835 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 17.00000 | arithmetic_mean_loss: 0.09892 | harmonic_mean_loss: 0.57257 | prediction_mean_pearson: 0.80726 | prediction_mean_spearman: 0.69816 | entropy_spearman: 0.41228 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 18.00000 | arithmetic_mean_loss: 0.09906 | harmonic_mean_loss: 0.57154 | prediction_mean_pearson: 0.80709 | prediction_mean_spearman: 0.69824 | entropy_spearman: 0.41377 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 19.00000 | arithmetic_mean_loss: 0.09898 | harmonic_mean_loss: 0.57001 | prediction_mean_pearson: 0.80777 | prediction_mean_spearman: 0.69894 | entropy_spearman: 0.41539 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 20.00000 | arithmetic_mean_loss: 0.09848 | harmonic_mean_loss: 0.56463 | prediction_mean_pearson: 0.80977 | prediction_mean_spearman: 0.70152 | entropy_spearman: 0.41919 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 21.00000 | arithmetic_mean_loss: 0.09865 | harmonic_mean_loss: 0.56380 | prediction_mean_pearson: 0.80962 | prediction_mean_spearman: 0.70098 | entropy_spearman: 0.41907 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 22.00000 | arithmetic_mean_loss: 0.09830 | harmonic_mean_loss: 0.56001 | prediction_mean_pearson: 0.81109 | prediction_mean_spearman: 0.70285 | entropy_spearman: 0.42117 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 23.00000 | arithmetic_mean_loss: 0.09841 | harmonic_mean_loss: 0.56081 | prediction_mean_pearson: 0.81084 | prediction_mean_spearman: 0.70239 | entropy_spearman: 0.42140 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 24.00000 | arithmetic_mean_loss: 0.09834 | harmonic_mean_loss: 0.55872 | prediction_mean_pearson: 0.81151 | prediction_mean_spearman: 0.70305 | entropy_spearman: 0.42266 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 25.00000 | arithmetic_mean_loss: 0.09800 | harmonic_mean_loss: 0.55535 | prediction_mean_pearson: 0.81281 | prediction_mean_spearman: 0.70489 | entropy_spearman: 0.42540 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 26.00000 | arithmetic_mean_loss: 0.09823 | harmonic_mean_loss: 0.55946 | prediction_mean_pearson: 0.81150 | prediction_mean_spearman: 0.70287 | entropy_spearman: 0.42547 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 27.00000 | arithmetic_mean_loss: 0.09837 | harmonic_mean_loss: 0.55847 | prediction_mean_pearson: 0.81159 | prediction_mean_spearman: 0.70269 | entropy_spearman: 0.42583 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 28.00000 | arithmetic_mean_loss: 0.09803 | harmonic_mean_loss: 0.55512 | prediction_mean_pearson: 0.81286 | prediction_mean_spearman: 0.70443 | entropy_spearman: 0.42827 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 29.00000 | arithmetic_mean_loss: 0.09820 | harmonic_mean_loss: 0.55708 | prediction_mean_pearson: 0.81222 | prediction_mean_spearman: 0.70354 | entropy_spearman: 0.42532 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 30.00000 | arithmetic_mean_loss: 0.09806 | harmonic_mean_loss: 0.55484 | prediction_mean_pearson: 0.81296 | prediction_mean_spearman: 0.70425 | entropy_spearman: 0.42667 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but the required `min_epochs=60` or `min_steps=None` has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 31.00000 | arithmetic_mean_loss: 0.09822 | harmonic_mean_loss: 0.55736 | prediction_mean_pearson: 0.81221 | prediction_mean_spearman: 0.70423 | entropy_spearman: 0.42597 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 32.00000 | arithmetic_mean_loss: 0.09822 | harmonic_mean_loss: 0.55580 | prediction_mean_pearson: 0.81270 | prediction_mean_spearman: 0.70444 | entropy_spearman: 0.42555 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 33.00000 | arithmetic_mean_loss: 0.09796 | harmonic_mean_loss: 0.55307 | prediction_mean_pearson: 0.81371 | prediction_mean_spearman: 0.70580 | entropy_spearman: 0.42739 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 34.00000 | arithmetic_mean_loss: 0.09782 | harmonic_mean_loss: 0.55187 | prediction_mean_pearson: 0.81415 | prediction_mean_spearman: 0.70576 | entropy_spearman: 0.42745 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 35.00000 | arithmetic_mean_loss: 0.09771 | harmonic_mean_loss: 0.54988 | prediction_mean_pearson: 0.81478 | prediction_mean_spearman: 0.70680 | entropy_spearman: 0.42779 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 36.00000 | arithmetic_mean_loss: 0.09746 | harmonic_mean_loss: 0.54762 | prediction_mean_pearson: 0.81565 | prediction_mean_spearman: 0.70804 | entropy_spearman: 0.42968 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 37.00000 | arithmetic_mean_loss: 0.09744 | harmonic_mean_loss: 0.54676 | prediction_mean_pearson: 0.81596 | prediction_mean_spearman: 0.70792 | entropy_spearman: 0.42851 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 38.00000 | arithmetic_mean_loss: 0.09727 | harmonic_mean_loss: 0.54479 | prediction_mean_pearson: 0.81670 | prediction_mean_spearman: 0.70893 | entropy_spearman: 0.42987 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 39.00000 | arithmetic_mean_loss: 0.09739 | harmonic_mean_loss: 0.54600 | prediction_mean_pearson: 0.81630 | prediction_mean_spearman: 0.70818 | entropy_spearman: 0.42854 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 40.00000 | arithmetic_mean_loss: 0.09733 | harmonic_mean_loss: 0.54539 | prediction_mean_pearson: 0.81660 | prediction_mean_spearman: 0.70852 | entropy_spearman: 0.42870 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 41.00000 | arithmetic_mean_loss: 0.09713 | harmonic_mean_loss: 0.54328 | prediction_mean_pearson: 0.81739 | prediction_mean_spearman: 0.70959 | entropy_spearman: 0.43026 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 42.00000 | arithmetic_mean_loss: 0.09734 | harmonic_mean_loss: 0.54387 | prediction_mean_pearson: 0.81709 | prediction_mean_spearman: 0.70859 | entropy_spearman: 0.42850 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 43.00000 | arithmetic_mean_loss: 0.09721 | harmonic_mean_loss: 0.54257 | prediction_mean_pearson: 0.81756 | prediction_mean_spearman: 0.70918 | entropy_spearman: 0.42933 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 44.00000 | arithmetic_mean_loss: 0.09763 | harmonic_mean_loss: 0.54501 | prediction_mean_pearson: 0.81670 | prediction_mean_spearman: 0.70721 | entropy_spearman: 0.42668 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 45.00000 | arithmetic_mean_loss: 0.09769 | harmonic_mean_loss: 0.54475 | prediction_mean_pearson: 0.81677 | prediction_mean_spearman: 0.70680 | entropy_spearman: 0.42668 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 46.00000 | arithmetic_mean_loss: 0.09750 | harmonic_mean_loss: 0.54325 | prediction_mean_pearson: 0.81737 | prediction_mean_spearman: 0.70776 | entropy_spearman: 0.42810 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 47.00000 | arithmetic_mean_loss: 0.09764 | harmonic_mean_loss: 0.54410 | prediction_mean_pearson: 0.81707 | prediction_mean_spearman: 0.70716 | entropy_spearman: 0.42785 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 48.00000 | arithmetic_mean_loss: 0.09763 | harmonic_mean_loss: 0.54322 | prediction_mean_pearson: 0.81731 | prediction_mean_spearman: 0.70741 | entropy_spearman: 0.42790 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 49.00000 | arithmetic_mean_loss: 0.09744 | harmonic_mean_loss: 0.54145 | prediction_mean_pearson: 0.81797 | prediction_mean_spearman: 0.70837 | entropy_spearman: 0.42936 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 50.00000 | arithmetic_mean_loss: 0.09775 | harmonic_mean_loss: 0.54295 | prediction_mean_pearson: 0.81734 | prediction_mean_spearman: 0.70734 | entropy_spearman: 0.42745 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 51.00000 | arithmetic_mean_loss: 0.09760 | harmonic_mean_loss: 0.54178 | prediction_mean_pearson: 0.81779 | prediction_mean_spearman: 0.70801 | entropy_spearman: 0.42844 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 52.00000 | arithmetic_mean_loss: 0.09766 | harmonic_mean_loss: 0.54246 | prediction_mean_pearson: 0.81752 | prediction_mean_spearman: 0.70713 | entropy_spearman: 0.42776 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 53.00000 | arithmetic_mean_loss: 0.09787 | harmonic_mean_loss: 0.54335 | prediction_mean_pearson: 0.81704 | prediction_mean_spearman: 0.70617 | entropy_spearman: 0.42812 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 54.00000 | arithmetic_mean_loss: 0.09770 | harmonic_mean_loss: 0.54199 | prediction_mean_pearson: 0.81757 | prediction_mean_spearman: 0.70695 | entropy_spearman: 0.42924 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 55.00000 | arithmetic_mean_loss: 0.09780 | harmonic_mean_loss: 0.54289 | prediction_mean_pearson: 0.81729 | prediction_mean_spearman: 0.70659 | entropy_spearman: 0.42809 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 56.00000 | arithmetic_mean_loss: 0.09771 | harmonic_mean_loss: 0.54272 | prediction_mean_pearson: 0.81738 | prediction_mean_spearman: 0.70631 | entropy_spearman: 0.42883 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 57.00000 | arithmetic_mean_loss: 0.09755 | harmonic_mean_loss: 0.54133 | prediction_mean_pearson: 0.81791 | prediction_mean_spearman: 0.70712 | entropy_spearman: 0.42999 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 58.00000 | arithmetic_mean_loss: 0.09753 | harmonic_mean_loss: 0.54129 | prediction_mean_pearson: 0.81791 | prediction_mean_spearman: 0.70686 | entropy_spearman: 0.43005 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 59.00000 | arithmetic_mean_loss: 0.09743 | harmonic_mean_loss: 0.54067 | prediction_mean_pearson: 0.81815 | prediction_mean_spearman: 0.70734 | entropy_spearman: 0.43072 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.08264666050672531\n",
      "      test_pearson          0.7583016157150269\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.08264666050672531, 'test_pearson': 0.7583016157150269}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BassetBranched(linear_dropout_p=0.11625456877954289,\n",
    "                      branched_activation='ReLU', branched_channels=140,\n",
    "                      branched_dropout_p=0.5757068086404574, \n",
    "                       n_outputs=len(train_dataset[0][1]),\n",
    "                      n_linear_layers=1, n_branched_layers=3, use_batch_norm=True,\n",
    "                      loss_criterion=L1KLmixed(beta=5.0, reduction='mean'))\n",
    "seq_model = CNNTransferLearning(model = model,\n",
    "    parent_weights = \"gs://tewhey-public-data/CODA_resources/my-model.epoch_5-step_19885.pkl\",\n",
    "                       frozen_epochs = 0,\n",
    "                          optimizer = \"Adam\",\n",
    "                          scheduler=\"CosineAnnealingWarmRestarts\",\n",
    "                          scheduler_interval=\"step\")\n",
    "\n",
    "callback_topmodel = pl.callbacks.ModelCheckpoint(monitor=\"prediction_mean_pearson\",\n",
    "                                                 save_top_k=1,\n",
    "                                                 dirpath=\"./Malinois\",\n",
    "                                                 filename=\"Malinois_max\")\n",
    "callback_es = pl.callbacks.early_stopping.EarlyStopping(monitor='prediction_mean_pearson', \n",
    "                                                        patience=30)\n",
    "\n",
    "logger = pl_loggers.TensorBoardLogger(\"./logs_Malinois\", name = \"Malinois_MPRA_ALL_HD_v2\")\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu', \n",
    "    devices=[0], \n",
    "    min_epochs=60, \n",
    "    max_epochs=200,\n",
    "    precision=16,\n",
    "    enable_progress_bar = False,\n",
    "    callbacks=[\n",
    "        #TQDMProgressBar(refresh_rate=50), \n",
    "        callback_es, \n",
    "        #callback_topmodel\n",
    "    ],\n",
    "    logger = logger\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(seq_model,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)\n",
    "trainer.test(seq_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc4f61-7f86-4fee-aa53-cf4cdb839258",
   "metadata": {},
   "source": [
    "# use t.Reverse(0.5) without reverse augs, original data 60 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73645741-eb7a-445a-95d5-60bce965e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "train_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    t.Reverse(0.5),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "val_test_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "\n",
    "target_transform = t_t.Compose([\n",
    "    #t_t.Normalize(mean = 0.500, std = 1.059) # original for Malinois \n",
    "])\n",
    "activity_columns = ['HepG2','SKNSH', \"K562\"]\n",
    "#stderr = ['lfcSE_k562', 'lfcSE_hepg2', 'lfcSE_sknsh']\n",
    "stderr = ['K562_lfcSE', 'HepG2_lfcSE', 'SKNSH_lfcSE']\n",
    "#seq = \"nt_sequence\"\n",
    "seq = \"sequence\"\n",
    "# load the data\n",
    "train_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, \"Y\"], \n",
    "                                split = \"train\",\n",
    "                              filtration = \"original\",\n",
    "                                duplication_cutoff = 0.5,\n",
    "                                #use_reverse_complement = True,\n",
    "                                stderr_columns = stderr,\n",
    "                                sequence_column = seq,\n",
    "                              transform = train_transform,\n",
    "                               target_transform = target_transform) \n",
    "\n",
    "val_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [7, 13], \n",
    "                              split = \"val\",\n",
    "                              filtration = \"original\",\n",
    "                              sequence_column = seq,\n",
    "                              stderr_columns = stderr,\n",
    "                              transform = val_test_transform,\n",
    "                             target_transform = target_transform) \n",
    "\n",
    "test_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [9, 21, \"X\"],\n",
    "                               split = \"test\",\n",
    "                              filtration = \"original\",\n",
    "                               sequence_column = seq,\n",
    "                               stderr_columns = stderr,\n",
    "                              transform = val_test_transform,\n",
    "                              target_transform = target_transform)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = NUM_WORKERS)\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb45ce96-8f2b-4714-894b-f250105dae11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MalinoisDataset of size 932104 (MpraDaraset)\n",
      "    Number of datapoints: 932104\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['1', '2', '3', '4', '5', '6', '8', '9', '10', '11', '12', '14', '15', '16', '17', '18', '20', '22', 'Y']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_log2FC', 'SKNSH_log2FC', 'K562_log2FC']\n",
      "    Target columns that can be used: {'K562_log2FC', 'HepG2_log2FC', 'SKNSH_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 58810 (MpraDaraset)\n",
      "    Number of datapoints: 58810\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['19', '21', 'X']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_log2FC', 'SKNSH_log2FC', 'K562_log2FC']\n",
      "    Target columns that can be used: {'K562_log2FC', 'HepG2_log2FC', 'SKNSH_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 62582 (MpraDaraset)\n",
      "    Number of datapoints: 62582\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['7', '13']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_log2FC', 'SKNSH_log2FC', 'K562_log2FC']\n",
      "    Target columns that can be used: {'K562_log2FC', 'HepG2_log2FC', 'SKNSH_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(\"=\"*50)\n",
    "print(val_dataset)\n",
    "print(\"=\"*50)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea307c9-5193-4c70-9d39-4413ad68a751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nios/miniconda3/envs/mpra/lib/python3.12/site-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type           | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model     | BassetBranched | 4.1 M  | train\n",
      "1 | criterion | L1KLmixed      | 0      | train\n",
      "-----------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.429    Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4107183 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nios/miniconda3/envs/mpra/lib/python3.12/site-packages/torch/nn/functional.py:2994: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.14147 | harmonic_mean_loss: 1.28705 | prediction_mean_pearson: -0.01738 | prediction_mean_spearman: -0.05536 | entropy_spearman: 0.06121 |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.13075 | harmonic_mean_loss: 1.21925 | prediction_mean_pearson: 0.64533 | prediction_mean_spearman: 0.54006 | entropy_spearman: 0.25293 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 1.00000 | arithmetic_mean_loss: 0.12069 | harmonic_mean_loss: 0.95701 | prediction_mean_pearson: 0.65824 | prediction_mean_spearman: 0.58750 | entropy_spearman: 0.29854 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 2.00000 | arithmetic_mean_loss: 0.11348 | harmonic_mean_loss: 0.83991 | prediction_mean_pearson: 0.70975 | prediction_mean_spearman: 0.63919 | entropy_spearman: 0.32778 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 3.00000 | arithmetic_mean_loss: 0.10832 | harmonic_mean_loss: 0.76177 | prediction_mean_pearson: 0.73920 | prediction_mean_spearman: 0.67145 | entropy_spearman: 0.35454 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 4.00000 | arithmetic_mean_loss: 0.10766 | harmonic_mean_loss: 0.73901 | prediction_mean_pearson: 0.74856 | prediction_mean_spearman: 0.67437 | entropy_spearman: 0.34224 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 5.00000 | arithmetic_mean_loss: 0.10643 | harmonic_mean_loss: 0.71334 | prediction_mean_pearson: 0.75796 | prediction_mean_spearman: 0.68009 | entropy_spearman: 0.34545 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 6.00000 | arithmetic_mean_loss: 0.10509 | harmonic_mean_loss: 0.69048 | prediction_mean_pearson: 0.76587 | prediction_mean_spearman: 0.68942 | entropy_spearman: 0.35734 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 7.00000 | arithmetic_mean_loss: 0.10322 | harmonic_mean_loss: 0.66641 | prediction_mean_pearson: 0.77533 | prediction_mean_spearman: 0.70040 | entropy_spearman: 0.37038 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 8.00000 | arithmetic_mean_loss: 0.10125 | harmonic_mean_loss: 0.64389 | prediction_mean_pearson: 0.78405 | prediction_mean_spearman: 0.71102 | entropy_spearman: 0.38353 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 9.00000 | arithmetic_mean_loss: 0.10072 | harmonic_mean_loss: 0.63442 | prediction_mean_pearson: 0.78706 | prediction_mean_spearman: 0.71416 | entropy_spearman: 0.38663 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 10.00000 | arithmetic_mean_loss: 0.09988 | harmonic_mean_loss: 0.62575 | prediction_mean_pearson: 0.79061 | prediction_mean_spearman: 0.71649 | entropy_spearman: 0.39401 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 11.00000 | arithmetic_mean_loss: 0.09884 | harmonic_mean_loss: 0.61430 | prediction_mean_pearson: 0.79512 | prediction_mean_spearman: 0.72079 | entropy_spearman: 0.40042 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 12.00000 | arithmetic_mean_loss: 0.09785 | harmonic_mean_loss: 0.60143 | prediction_mean_pearson: 0.80012 | prediction_mean_spearman: 0.72648 | entropy_spearman: 0.40751 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 13.00000 | arithmetic_mean_loss: 0.09675 | harmonic_mean_loss: 0.58813 | prediction_mean_pearson: 0.80518 | prediction_mean_spearman: 0.73218 | entropy_spearman: 0.41477 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 14.00000 | arithmetic_mean_loss: 0.09660 | harmonic_mean_loss: 0.58689 | prediction_mean_pearson: 0.80648 | prediction_mean_spearman: 0.73141 | entropy_spearman: 0.41719 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 15.00000 | arithmetic_mean_loss: 0.09629 | harmonic_mean_loss: 0.57946 | prediction_mean_pearson: 0.80886 | prediction_mean_spearman: 0.73358 | entropy_spearman: 0.41885 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 16.00000 | arithmetic_mean_loss: 0.09568 | harmonic_mean_loss: 0.57069 | prediction_mean_pearson: 0.81176 | prediction_mean_spearman: 0.73684 | entropy_spearman: 0.42284 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 17.00000 | arithmetic_mean_loss: 0.09489 | harmonic_mean_loss: 0.56144 | prediction_mean_pearson: 0.81513 | prediction_mean_spearman: 0.74063 | entropy_spearman: 0.42796 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 18.00000 | arithmetic_mean_loss: 0.09492 | harmonic_mean_loss: 0.56019 | prediction_mean_pearson: 0.81562 | prediction_mean_spearman: 0.73914 | entropy_spearman: 0.42683 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 19.00000 | arithmetic_mean_loss: 0.09482 | harmonic_mean_loss: 0.55605 | prediction_mean_pearson: 0.81690 | prediction_mean_spearman: 0.74021 | entropy_spearman: 0.42813 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 20.00000 | arithmetic_mean_loss: 0.09458 | harmonic_mean_loss: 0.55169 | prediction_mean_pearson: 0.81850 | prediction_mean_spearman: 0.74186 | entropy_spearman: 0.42939 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 21.00000 | arithmetic_mean_loss: 0.09414 | harmonic_mean_loss: 0.54700 | prediction_mean_pearson: 0.82059 | prediction_mean_spearman: 0.74433 | entropy_spearman: 0.43236 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 22.00000 | arithmetic_mean_loss: 0.09355 | harmonic_mean_loss: 0.54049 | prediction_mean_pearson: 0.82298 | prediction_mean_spearman: 0.74726 | entropy_spearman: 0.43611 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 23.00000 | arithmetic_mean_loss: 0.09357 | harmonic_mean_loss: 0.54096 | prediction_mean_pearson: 0.82309 | prediction_mean_spearman: 0.74741 | entropy_spearman: 0.43640 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 24.00000 | arithmetic_mean_loss: 0.09393 | harmonic_mean_loss: 0.54036 | prediction_mean_pearson: 0.82305 | prediction_mean_spearman: 0.74558 | entropy_spearman: 0.43401 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 25.00000 | arithmetic_mean_loss: 0.09361 | harmonic_mean_loss: 0.53649 | prediction_mean_pearson: 0.82458 | prediction_mean_spearman: 0.74718 | entropy_spearman: 0.43610 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 26.00000 | arithmetic_mean_loss: 0.09317 | harmonic_mean_loss: 0.53176 | prediction_mean_pearson: 0.82635 | prediction_mean_spearman: 0.74917 | entropy_spearman: 0.43887 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 27.00000 | arithmetic_mean_loss: 0.09269 | harmonic_mean_loss: 0.52656 | prediction_mean_pearson: 0.82819 | prediction_mean_spearman: 0.75150 | entropy_spearman: 0.44193 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 28.00000 | arithmetic_mean_loss: 0.09289 | harmonic_mean_loss: 0.52716 | prediction_mean_pearson: 0.82819 | prediction_mean_spearman: 0.75072 | entropy_spearman: 0.43815 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 29.00000 | arithmetic_mean_loss: 0.09311 | harmonic_mean_loss: 0.52573 | prediction_mean_pearson: 0.82853 | prediction_mean_spearman: 0.75082 | entropy_spearman: 0.43471 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 30.00000 | arithmetic_mean_loss: 0.09290 | harmonic_mean_loss: 0.52255 | prediction_mean_pearson: 0.82935 | prediction_mean_spearman: 0.75186 | entropy_spearman: 0.43682 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but the required `min_epochs=60` or `min_steps=None` has not been met. Training will continue...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 31.00000 | arithmetic_mean_loss: 0.09256 | harmonic_mean_loss: 0.51905 | prediction_mean_pearson: 0.83063 | prediction_mean_spearman: 0.75361 | entropy_spearman: 0.43926 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 32.00000 | arithmetic_mean_loss: 0.09217 | harmonic_mean_loss: 0.51502 | prediction_mean_pearson: 0.83203 | prediction_mean_spearman: 0.75552 | entropy_spearman: 0.44184 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 33.00000 | arithmetic_mean_loss: 0.09239 | harmonic_mean_loss: 0.51490 | prediction_mean_pearson: 0.83157 | prediction_mean_spearman: 0.75478 | entropy_spearman: 0.44112 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 34.00000 | arithmetic_mean_loss: 0.09234 | harmonic_mean_loss: 0.51484 | prediction_mean_pearson: 0.83180 | prediction_mean_spearman: 0.75465 | entropy_spearman: 0.44070 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 35.00000 | arithmetic_mean_loss: 0.09213 | harmonic_mean_loss: 0.51194 | prediction_mean_pearson: 0.83262 | prediction_mean_spearman: 0.75575 | entropy_spearman: 0.44249 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 36.00000 | arithmetic_mean_loss: 0.09180 | harmonic_mean_loss: 0.50840 | prediction_mean_pearson: 0.83390 | prediction_mean_spearman: 0.75734 | entropy_spearman: 0.44473 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 37.00000 | arithmetic_mean_loss: 0.09206 | harmonic_mean_loss: 0.50865 | prediction_mean_pearson: 0.83372 | prediction_mean_spearman: 0.75656 | entropy_spearman: 0.44183 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 38.00000 | arithmetic_mean_loss: 0.09200 | harmonic_mean_loss: 0.50764 | prediction_mean_pearson: 0.83417 | prediction_mean_spearman: 0.75708 | entropy_spearman: 0.44248 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 39.00000 | arithmetic_mean_loss: 0.09200 | harmonic_mean_loss: 0.50849 | prediction_mean_pearson: 0.83412 | prediction_mean_spearman: 0.75755 | entropy_spearman: 0.44348 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 40.00000 | arithmetic_mean_loss: 0.09178 | harmonic_mean_loss: 0.50576 | prediction_mean_pearson: 0.83504 | prediction_mean_spearman: 0.75866 | entropy_spearman: 0.44498 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 41.00000 | arithmetic_mean_loss: 0.09148 | harmonic_mean_loss: 0.50279 | prediction_mean_pearson: 0.83612 | prediction_mean_spearman: 0.76003 | entropy_spearman: 0.44700 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 42.00000 | arithmetic_mean_loss: 0.09167 | harmonic_mean_loss: 0.50312 | prediction_mean_pearson: 0.83595 | prediction_mean_spearman: 0.75895 | entropy_spearman: 0.44706 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 43.00000 | arithmetic_mean_loss: 0.09177 | harmonic_mean_loss: 0.50250 | prediction_mean_pearson: 0.83591 | prediction_mean_spearman: 0.75857 | entropy_spearman: 0.44697 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 44.00000 | arithmetic_mean_loss: 0.09166 | harmonic_mean_loss: 0.50076 | prediction_mean_pearson: 0.83657 | prediction_mean_spearman: 0.75916 | entropy_spearman: 0.44795 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 45.00000 | arithmetic_mean_loss: 0.09143 | harmonic_mean_loss: 0.49856 | prediction_mean_pearson: 0.83737 | prediction_mean_spearman: 0.76021 | entropy_spearman: 0.44937 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 46.00000 | arithmetic_mean_loss: 0.09117 | harmonic_mean_loss: 0.49598 | prediction_mean_pearson: 0.83830 | prediction_mean_spearman: 0.76140 | entropy_spearman: 0.45103 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 47.00000 | arithmetic_mean_loss: 0.09113 | harmonic_mean_loss: 0.49564 | prediction_mean_pearson: 0.83851 | prediction_mean_spearman: 0.76119 | entropy_spearman: 0.45127 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 48.00000 | arithmetic_mean_loss: 0.09109 | harmonic_mean_loss: 0.49588 | prediction_mean_pearson: 0.83858 | prediction_mean_spearman: 0.76136 | entropy_spearman: 0.45199 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 49.00000 | arithmetic_mean_loss: 0.09116 | harmonic_mean_loss: 0.49512 | prediction_mean_pearson: 0.83863 | prediction_mean_spearman: 0.76100 | entropy_spearman: 0.45275 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 50.00000 | arithmetic_mean_loss: 0.09096 | harmonic_mean_loss: 0.49289 | prediction_mean_pearson: 0.83940 | prediction_mean_spearman: 0.76199 | entropy_spearman: 0.45409 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 51.00000 | arithmetic_mean_loss: 0.09144 | harmonic_mean_loss: 0.49587 | prediction_mean_pearson: 0.83785 | prediction_mean_spearman: 0.76078 | entropy_spearman: 0.45282 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 52.00000 | arithmetic_mean_loss: 0.09146 | harmonic_mean_loss: 0.49530 | prediction_mean_pearson: 0.83811 | prediction_mean_spearman: 0.76101 | entropy_spearman: 0.45293 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 53.00000 | arithmetic_mean_loss: 0.09141 | harmonic_mean_loss: 0.49447 | prediction_mean_pearson: 0.83837 | prediction_mean_spearman: 0.76132 | entropy_spearman: 0.45321 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 54.00000 | arithmetic_mean_loss: 0.09125 | harmonic_mean_loss: 0.49314 | prediction_mean_pearson: 0.83889 | prediction_mean_spearman: 0.76200 | entropy_spearman: 0.45401 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 55.00000 | arithmetic_mean_loss: 0.09104 | harmonic_mean_loss: 0.49103 | prediction_mean_pearson: 0.83962 | prediction_mean_spearman: 0.76292 | entropy_spearman: 0.45531 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 56.00000 | arithmetic_mean_loss: 0.09113 | harmonic_mean_loss: 0.49101 | prediction_mean_pearson: 0.83947 | prediction_mean_spearman: 0.76250 | entropy_spearman: 0.45525 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 57.00000 | arithmetic_mean_loss: 0.09116 | harmonic_mean_loss: 0.49041 | prediction_mean_pearson: 0.83969 | prediction_mean_spearman: 0.76232 | entropy_spearman: 0.45488 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 58.00000 | arithmetic_mean_loss: 0.09108 | harmonic_mean_loss: 0.48990 | prediction_mean_pearson: 0.83993 | prediction_mean_spearman: 0.76274 | entropy_spearman: 0.45547 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 59.00000 | arithmetic_mean_loss: 0.09092 | harmonic_mean_loss: 0.48810 | prediction_mean_pearson: 0.84054 | prediction_mean_spearman: 0.76347 | entropy_spearman: 0.45626 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.07348258048295975\n",
      "      test_pearson          0.8333613276481628\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.07348258048295975, 'test_pearson': 0.8333613276481628}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BassetBranched(linear_dropout_p=0.11625456877954289,\n",
    "                      branched_activation='ReLU', branched_channels=140,\n",
    "                      branched_dropout_p=0.5757068086404574, \n",
    "                       n_outputs=len(train_dataset[0][1]),\n",
    "                      n_linear_layers=1, n_branched_layers=3, use_batch_norm=True,\n",
    "                      loss_criterion=L1KLmixed(beta=5.0, reduction='mean'))\n",
    "seq_model = CNNTransferLearning(model = model,\n",
    "    parent_weights = \"gs://tewhey-public-data/CODA_resources/my-model.epoch_5-step_19885.pkl\",\n",
    "                       frozen_epochs = 0,\n",
    "                          optimizer = \"Adam\",\n",
    "                          scheduler=\"CosineAnnealingWarmRestarts\",\n",
    "                          scheduler_interval=\"step\")\n",
    "\n",
    "callback_topmodel = pl.callbacks.ModelCheckpoint(monitor=\"prediction_mean_pearson\",\n",
    "                                                 save_top_k=1,\n",
    "                                                 dirpath=\"./Malinois\",\n",
    "                                                 filename=\"Malinois_max\")\n",
    "callback_es = pl.callbacks.early_stopping.EarlyStopping(monitor='prediction_mean_pearson', \n",
    "                                                        patience=30)\n",
    "\n",
    "logger = pl_loggers.TensorBoardLogger(\"./logs_Malinois\", name = \"Malinois_without_rev_augs_with_use_t.Revese(0.5)\")\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu', \n",
    "    devices=[0], \n",
    "    min_epochs=60, \n",
    "    max_epochs=200,\n",
    "    precision=16,\n",
    "    enable_progress_bar = False,\n",
    "    callbacks=[\n",
    "        #TQDMProgressBar(refresh_rate=50), \n",
    "        callback_es, \n",
    "        #callback_topmodel\n",
    "    ],\n",
    "    logger = logger\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(seq_model,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)\n",
    "trainer.test(seq_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc74582-deba-46fa-8088-41f81847675a",
   "metadata": {},
   "source": [
    "### 0.83 the best result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99d2eb-8892-47b5-89e7-72f32b38638b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# train for 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e48cb-ac88-4352-99c4-b29a81658192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nios/miniconda3/envs/mpra/lib/python3.12/site-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type           | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model     | BassetBranched | 4.1 M  | train\n",
      "1 | criterion | L1KLmixed      | 0      | train\n",
      "-----------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.429    Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4107183 parameters\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.15307 | harmonic_mean_loss: 1.77294 | prediction_mean_pearson: 0.00341 | prediction_mean_spearman: 0.00123 | entropy_spearman: 0.07261 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nios/miniconda3/envs/mpra/lib/python3.12/site-packages/torch/nn/functional.py:2994: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.12907 | harmonic_mean_loss: 1.03301 | prediction_mean_pearson: 0.67402 | prediction_mean_spearman: 0.57775 | entropy_spearman: 0.23495 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 1.00000 | arithmetic_mean_loss: 0.12100 | harmonic_mean_loss: 0.89690 | prediction_mean_pearson: 0.72479 | prediction_mean_spearman: 0.64118 | entropy_spearman: 0.31507 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 2.00000 | arithmetic_mean_loss: 0.11620 | harmonic_mean_loss: 0.85948 | prediction_mean_pearson: 0.74573 | prediction_mean_spearman: 0.65851 | entropy_spearman: 0.35172 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 3.00000 | arithmetic_mean_loss: 0.11157 | harmonic_mean_loss: 0.79181 | prediction_mean_pearson: 0.76543 | prediction_mean_spearman: 0.68625 | entropy_spearman: 0.37473 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 4.00000 | arithmetic_mean_loss: 0.11128 | harmonic_mean_loss: 0.78552 | prediction_mean_pearson: 0.76870 | prediction_mean_spearman: 0.69152 | entropy_spearman: 0.37634 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 5.00000 | arithmetic_mean_loss: 0.11074 | harmonic_mean_loss: 0.76403 | prediction_mean_pearson: 0.77410 | prediction_mean_spearman: 0.69775 | entropy_spearman: 0.37050 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 6.00000 | arithmetic_mean_loss: 0.10918 | harmonic_mean_loss: 0.74079 | prediction_mean_pearson: 0.78196 | prediction_mean_spearman: 0.70668 | entropy_spearman: 0.37976 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 7.00000 | arithmetic_mean_loss: 0.10735 | harmonic_mean_loss: 0.71458 | prediction_mean_pearson: 0.79098 | prediction_mean_spearman: 0.71611 | entropy_spearman: 0.39265 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 8.00000 | arithmetic_mean_loss: 0.10539 | harmonic_mean_loss: 0.68892 | prediction_mean_pearson: 0.79921 | prediction_mean_spearman: 0.72555 | entropy_spearman: 0.40494 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 9.00000 | arithmetic_mean_loss: 0.10596 | harmonic_mean_loss: 0.70285 | prediction_mean_pearson: 0.79671 | prediction_mean_spearman: 0.71915 | entropy_spearman: 0.40813 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 10.00000 | arithmetic_mean_loss: 0.10538 | harmonic_mean_loss: 0.69538 | prediction_mean_pearson: 0.79995 | prediction_mean_spearman: 0.72224 | entropy_spearman: 0.41134 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 11.00000 | arithmetic_mean_loss: 0.10477 | harmonic_mean_loss: 0.68153 | prediction_mean_pearson: 0.80306 | prediction_mean_spearman: 0.72481 | entropy_spearman: 0.41291 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 12.00000 | arithmetic_mean_loss: 0.10358 | harmonic_mean_loss: 0.66632 | prediction_mean_pearson: 0.80782 | prediction_mean_spearman: 0.73071 | entropy_spearman: 0.41939 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 13.00000 | arithmetic_mean_loss: 0.10242 | harmonic_mean_loss: 0.65102 | prediction_mean_pearson: 0.81213 | prediction_mean_spearman: 0.73636 | entropy_spearman: 0.42611 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 14.00000 | arithmetic_mean_loss: 0.10232 | harmonic_mean_loss: 0.64695 | prediction_mean_pearson: 0.81375 | prediction_mean_spearman: 0.73707 | entropy_spearman: 0.42489 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 15.00000 | arithmetic_mean_loss: 0.10212 | harmonic_mean_loss: 0.64345 | prediction_mean_pearson: 0.81532 | prediction_mean_spearman: 0.73922 | entropy_spearman: 0.42745 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 16.00000 | arithmetic_mean_loss: 0.10143 | harmonic_mean_loss: 0.63429 | prediction_mean_pearson: 0.81811 | prediction_mean_spearman: 0.74220 | entropy_spearman: 0.43187 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 17.00000 | arithmetic_mean_loss: 0.10058 | harmonic_mean_loss: 0.62383 | prediction_mean_pearson: 0.82105 | prediction_mean_spearman: 0.74588 | entropy_spearman: 0.43701 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 18.00000 | arithmetic_mean_loss: 0.10062 | harmonic_mean_loss: 0.62243 | prediction_mean_pearson: 0.82112 | prediction_mean_spearman: 0.74515 | entropy_spearman: 0.43624 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 19.00000 | arithmetic_mean_loss: 0.10057 | harmonic_mean_loss: 0.62239 | prediction_mean_pearson: 0.82173 | prediction_mean_spearman: 0.74582 | entropy_spearman: 0.43685 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 20.00000 | arithmetic_mean_loss: 0.10042 | harmonic_mean_loss: 0.61659 | prediction_mean_pearson: 0.82221 | prediction_mean_spearman: 0.74625 | entropy_spearman: 0.43887 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 21.00000 | arithmetic_mean_loss: 0.09995 | harmonic_mean_loss: 0.61109 | prediction_mean_pearson: 0.82416 | prediction_mean_spearman: 0.74865 | entropy_spearman: 0.44130 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 22.00000 | arithmetic_mean_loss: 0.09932 | harmonic_mean_loss: 0.60356 | prediction_mean_pearson: 0.82659 | prediction_mean_spearman: 0.75145 | entropy_spearman: 0.44505 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 23.00000 | arithmetic_mean_loss: 0.09935 | harmonic_mean_loss: 0.60313 | prediction_mean_pearson: 0.82683 | prediction_mean_spearman: 0.75156 | entropy_spearman: 0.44463 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 24.00000 | arithmetic_mean_loss: 0.09936 | harmonic_mean_loss: 0.60059 | prediction_mean_pearson: 0.82736 | prediction_mean_spearman: 0.75171 | entropy_spearman: 0.44324 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 25.00000 | arithmetic_mean_loss: 0.09907 | harmonic_mean_loss: 0.59595 | prediction_mean_pearson: 0.82849 | prediction_mean_spearman: 0.75286 | entropy_spearman: 0.44451 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 26.00000 | arithmetic_mean_loss: 0.09862 | harmonic_mean_loss: 0.59061 | prediction_mean_pearson: 0.83013 | prediction_mean_spearman: 0.75469 | entropy_spearman: 0.44719 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 27.00000 | arithmetic_mean_loss: 0.09815 | harmonic_mean_loss: 0.58503 | prediction_mean_pearson: 0.83187 | prediction_mean_spearman: 0.75686 | entropy_spearman: 0.45017 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 28.00000 | arithmetic_mean_loss: 0.09813 | harmonic_mean_loss: 0.58374 | prediction_mean_pearson: 0.83223 | prediction_mean_spearman: 0.75693 | entropy_spearman: 0.45032 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 29.00000 | arithmetic_mean_loss: 0.09826 | harmonic_mean_loss: 0.58402 | prediction_mean_pearson: 0.83209 | prediction_mean_spearman: 0.75494 | entropy_spearman: 0.44801 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 30.00000 | arithmetic_mean_loss: 0.09801 | harmonic_mean_loss: 0.58067 | prediction_mean_pearson: 0.83312 | prediction_mean_spearman: 0.75612 | entropy_spearman: 0.44942 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 31.00000 | arithmetic_mean_loss: 0.09767 | harmonic_mean_loss: 0.57715 | prediction_mean_pearson: 0.83434 | prediction_mean_spearman: 0.75766 | entropy_spearman: 0.45172 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 32.00000 | arithmetic_mean_loss: 0.09729 | harmonic_mean_loss: 0.57271 | prediction_mean_pearson: 0.83567 | prediction_mean_spearman: 0.75946 | entropy_spearman: 0.45428 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 33.00000 | arithmetic_mean_loss: 0.09766 | harmonic_mean_loss: 0.57392 | prediction_mean_pearson: 0.83423 | prediction_mean_spearman: 0.75798 | entropy_spearman: 0.45311 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 34.00000 | arithmetic_mean_loss: 0.09764 | harmonic_mean_loss: 0.57187 | prediction_mean_pearson: 0.83467 | prediction_mean_spearman: 0.75787 | entropy_spearman: 0.45322 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 35.00000 | arithmetic_mean_loss: 0.09745 | harmonic_mean_loss: 0.56887 | prediction_mean_pearson: 0.83530 | prediction_mean_spearman: 0.75890 | entropy_spearman: 0.45480 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 36.00000 | arithmetic_mean_loss: 0.09712 | harmonic_mean_loss: 0.56548 | prediction_mean_pearson: 0.83640 | prediction_mean_spearman: 0.76040 | entropy_spearman: 0.45683 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 37.00000 | arithmetic_mean_loss: 0.09745 | harmonic_mean_loss: 0.56692 | prediction_mean_pearson: 0.83596 | prediction_mean_spearman: 0.75906 | entropy_spearman: 0.45337 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 38.00000 | arithmetic_mean_loss: 0.09751 | harmonic_mean_loss: 0.56882 | prediction_mean_pearson: 0.83565 | prediction_mean_spearman: 0.75816 | entropy_spearman: 0.45338 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 39.00000 | arithmetic_mean_loss: 0.09740 | harmonic_mean_loss: 0.56740 | prediction_mean_pearson: 0.83619 | prediction_mean_spearman: 0.75870 | entropy_spearman: 0.45371 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 40.00000 | arithmetic_mean_loss: 0.09716 | harmonic_mean_loss: 0.56449 | prediction_mean_pearson: 0.83709 | prediction_mean_spearman: 0.75972 | entropy_spearman: 0.45508 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 41.00000 | arithmetic_mean_loss: 0.09686 | harmonic_mean_loss: 0.56110 | prediction_mean_pearson: 0.83811 | prediction_mean_spearman: 0.76109 | entropy_spearman: 0.45706 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 42.00000 | arithmetic_mean_loss: 0.09740 | harmonic_mean_loss: 0.56340 | prediction_mean_pearson: 0.83657 | prediction_mean_spearman: 0.75825 | entropy_spearman: 0.45650 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 43.00000 | arithmetic_mean_loss: 0.09731 | harmonic_mean_loss: 0.56215 | prediction_mean_pearson: 0.83694 | prediction_mean_spearman: 0.75873 | entropy_spearman: 0.45661 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 44.00000 | arithmetic_mean_loss: 0.09723 | harmonic_mean_loss: 0.56179 | prediction_mean_pearson: 0.83723 | prediction_mean_spearman: 0.75904 | entropy_spearman: 0.45740 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 45.00000 | arithmetic_mean_loss: 0.09701 | harmonic_mean_loss: 0.55916 | prediction_mean_pearson: 0.83805 | prediction_mean_spearman: 0.76014 | entropy_spearman: 0.45887 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 46.00000 | arithmetic_mean_loss: 0.09674 | harmonic_mean_loss: 0.55621 | prediction_mean_pearson: 0.83895 | prediction_mean_spearman: 0.76141 | entropy_spearman: 0.46053 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 47.00000 | arithmetic_mean_loss: 0.09689 | harmonic_mean_loss: 0.55832 | prediction_mean_pearson: 0.83847 | prediction_mean_spearman: 0.76088 | entropy_spearman: 0.45938 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 48.00000 | arithmetic_mean_loss: 0.09680 | harmonic_mean_loss: 0.55686 | prediction_mean_pearson: 0.83876 | prediction_mean_spearman: 0.76129 | entropy_spearman: 0.45993 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 49.00000 | arithmetic_mean_loss: 0.09667 | harmonic_mean_loss: 0.55500 | prediction_mean_pearson: 0.83935 | prediction_mean_spearman: 0.76191 | entropy_spearman: 0.46089 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 50.00000 | arithmetic_mean_loss: 0.09644 | harmonic_mean_loss: 0.55238 | prediction_mean_pearson: 0.84017 | prediction_mean_spearman: 0.76295 | entropy_spearman: 0.46223 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 51.00000 | arithmetic_mean_loss: 0.09715 | harmonic_mean_loss: 0.55747 | prediction_mean_pearson: 0.83785 | prediction_mean_spearman: 0.76068 | entropy_spearman: 0.45852 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 52.00000 | arithmetic_mean_loss: 0.09732 | harmonic_mean_loss: 0.56008 | prediction_mean_pearson: 0.83714 | prediction_mean_spearman: 0.75965 | entropy_spearman: 0.45776 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 53.00000 | arithmetic_mean_loss: 0.09726 | harmonic_mean_loss: 0.55927 | prediction_mean_pearson: 0.83750 | prediction_mean_spearman: 0.76006 | entropy_spearman: 0.45831 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 54.00000 | arithmetic_mean_loss: 0.09707 | harmonic_mean_loss: 0.55735 | prediction_mean_pearson: 0.83815 | prediction_mean_spearman: 0.76093 | entropy_spearman: 0.45936 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 55.00000 | arithmetic_mean_loss: 0.09685 | harmonic_mean_loss: 0.55496 | prediction_mean_pearson: 0.83890 | prediction_mean_spearman: 0.76194 | entropy_spearman: 0.46071 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 56.00000 | arithmetic_mean_loss: 0.09713 | harmonic_mean_loss: 0.55622 | prediction_mean_pearson: 0.83814 | prediction_mean_spearman: 0.76106 | entropy_spearman: 0.45986 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 57.00000 | arithmetic_mean_loss: 0.09707 | harmonic_mean_loss: 0.55535 | prediction_mean_pearson: 0.83837 | prediction_mean_spearman: 0.76140 | entropy_spearman: 0.45985 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 58.00000 | arithmetic_mean_loss: 0.09701 | harmonic_mean_loss: 0.55494 | prediction_mean_pearson: 0.83857 | prediction_mean_spearman: 0.76158 | entropy_spearman: 0.46047 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 59.00000 | arithmetic_mean_loss: 0.09684 | harmonic_mean_loss: 0.55301 | prediction_mean_pearson: 0.83922 | prediction_mean_spearman: 0.76236 | entropy_spearman: 0.46139 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 60.00000 | arithmetic_mean_loss: 0.09662 | harmonic_mean_loss: 0.55075 | prediction_mean_pearson: 0.83994 | prediction_mean_spearman: 0.76331 | entropy_spearman: 0.46268 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 61.00000 | arithmetic_mean_loss: 0.09660 | harmonic_mean_loss: 0.55024 | prediction_mean_pearson: 0.84010 | prediction_mean_spearman: 0.76342 | entropy_spearman: 0.46279 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 62.00000 | arithmetic_mean_loss: 0.09655 | harmonic_mean_loss: 0.54955 | prediction_mean_pearson: 0.84033 | prediction_mean_spearman: 0.76367 | entropy_spearman: 0.46295 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 63.00000 | arithmetic_mean_loss: 0.09643 | harmonic_mean_loss: 0.54810 | prediction_mean_pearson: 0.84073 | prediction_mean_spearman: 0.76424 | entropy_spearman: 0.46364 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 64.00000 | arithmetic_mean_loss: 0.09628 | harmonic_mean_loss: 0.54676 | prediction_mean_pearson: 0.84122 | prediction_mean_spearman: 0.76492 | entropy_spearman: 0.46460 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 65.00000 | arithmetic_mean_loss: 0.09609 | harmonic_mean_loss: 0.54479 | prediction_mean_pearson: 0.84185 | prediction_mean_spearman: 0.76574 | entropy_spearman: 0.46578 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 66.00000 | arithmetic_mean_loss: 0.09618 | harmonic_mean_loss: 0.54679 | prediction_mean_pearson: 0.84141 | prediction_mean_spearman: 0.76527 | entropy_spearman: 0.46525 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 67.00000 | arithmetic_mean_loss: 0.09625 | harmonic_mean_loss: 0.54650 | prediction_mean_pearson: 0.84148 | prediction_mean_spearman: 0.76501 | entropy_spearman: 0.46428 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 68.00000 | arithmetic_mean_loss: 0.09613 | harmonic_mean_loss: 0.54520 | prediction_mean_pearson: 0.84190 | prediction_mean_spearman: 0.76558 | entropy_spearman: 0.46495 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 69.00000 | arithmetic_mean_loss: 0.09596 | harmonic_mean_loss: 0.54350 | prediction_mean_pearson: 0.84246 | prediction_mean_spearman: 0.76632 | entropy_spearman: 0.46600 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 70.00000 | arithmetic_mean_loss: 0.09609 | harmonic_mean_loss: 0.54447 | prediction_mean_pearson: 0.84220 | prediction_mean_spearman: 0.76565 | entropy_spearman: 0.46478 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 71.00000 | arithmetic_mean_loss: 0.09614 | harmonic_mean_loss: 0.54547 | prediction_mean_pearson: 0.84199 | prediction_mean_spearman: 0.76560 | entropy_spearman: 0.46467 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 72.00000 | arithmetic_mean_loss: 0.09609 | harmonic_mean_loss: 0.54471 | prediction_mean_pearson: 0.84224 | prediction_mean_spearman: 0.76587 | entropy_spearman: 0.46514 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 73.00000 | arithmetic_mean_loss: 0.09599 | harmonic_mean_loss: 0.54378 | prediction_mean_pearson: 0.84262 | prediction_mean_spearman: 0.76635 | entropy_spearman: 0.46600 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 74.00000 | arithmetic_mean_loss: 0.09583 | harmonic_mean_loss: 0.54213 | prediction_mean_pearson: 0.84316 | prediction_mean_spearman: 0.76706 | entropy_spearman: 0.46701 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 75.00000 | arithmetic_mean_loss: 0.09596 | harmonic_mean_loss: 0.54474 | prediction_mean_pearson: 0.84250 | prediction_mean_spearman: 0.76659 | entropy_spearman: 0.46699 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 76.00000 | arithmetic_mean_loss: 0.09596 | harmonic_mean_loss: 0.54423 | prediction_mean_pearson: 0.84255 | prediction_mean_spearman: 0.76660 | entropy_spearman: 0.46690 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 77.00000 | arithmetic_mean_loss: 0.09587 | harmonic_mean_loss: 0.54314 | prediction_mean_pearson: 0.84287 | prediction_mean_spearman: 0.76694 | entropy_spearman: 0.46738 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 78.00000 | arithmetic_mean_loss: 0.09575 | harmonic_mean_loss: 0.54184 | prediction_mean_pearson: 0.84330 | prediction_mean_spearman: 0.76754 | entropy_spearman: 0.46810 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 79.00000 | arithmetic_mean_loss: 0.09560 | harmonic_mean_loss: 0.54029 | prediction_mean_pearson: 0.84379 | prediction_mean_spearman: 0.76821 | entropy_spearman: 0.46900 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 80.00000 | arithmetic_mean_loss: 0.09565 | harmonic_mean_loss: 0.54046 | prediction_mean_pearson: 0.84375 | prediction_mean_spearman: 0.76768 | entropy_spearman: 0.46792 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 81.00000 | arithmetic_mean_loss: 0.09567 | harmonic_mean_loss: 0.54024 | prediction_mean_pearson: 0.84384 | prediction_mean_spearman: 0.76767 | entropy_spearman: 0.46798 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 82.00000 | arithmetic_mean_loss: 0.09558 | harmonic_mean_loss: 0.53903 | prediction_mean_pearson: 0.84416 | prediction_mean_spearman: 0.76809 | entropy_spearman: 0.46856 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 83.00000 | arithmetic_mean_loss: 0.09545 | harmonic_mean_loss: 0.53769 | prediction_mean_pearson: 0.84460 | prediction_mean_spearman: 0.76864 | entropy_spearman: 0.46929 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 84.00000 | arithmetic_mean_loss: 0.09530 | harmonic_mean_loss: 0.53618 | prediction_mean_pearson: 0.84508 | prediction_mean_spearman: 0.76926 | entropy_spearman: 0.47017 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 85.00000 | arithmetic_mean_loss: 0.09529 | harmonic_mean_loss: 0.53589 | prediction_mean_pearson: 0.84521 | prediction_mean_spearman: 0.76931 | entropy_spearman: 0.47013 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 86.00000 | arithmetic_mean_loss: 0.09527 | harmonic_mean_loss: 0.53529 | prediction_mean_pearson: 0.84538 | prediction_mean_spearman: 0.76948 | entropy_spearman: 0.47017 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 87.00000 | arithmetic_mean_loss: 0.09519 | harmonic_mean_loss: 0.53463 | prediction_mean_pearson: 0.84564 | prediction_mean_spearman: 0.76984 | entropy_spearman: 0.47065 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 88.00000 | arithmetic_mean_loss: 0.09507 | harmonic_mean_loss: 0.53343 | prediction_mean_pearson: 0.84605 | prediction_mean_spearman: 0.77038 | entropy_spearman: 0.47141 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 89.00000 | arithmetic_mean_loss: 0.09508 | harmonic_mean_loss: 0.53362 | prediction_mean_pearson: 0.84600 | prediction_mean_spearman: 0.77005 | entropy_spearman: 0.47147 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 90.00000 | arithmetic_mean_loss: 0.09509 | harmonic_mean_loss: 0.53335 | prediction_mean_pearson: 0.84606 | prediction_mean_spearman: 0.77005 | entropy_spearman: 0.47144 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 91.00000 | arithmetic_mean_loss: 0.09504 | harmonic_mean_loss: 0.53271 | prediction_mean_pearson: 0.84623 | prediction_mean_spearman: 0.77027 | entropy_spearman: 0.47160 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 92.00000 | arithmetic_mean_loss: 0.09496 | harmonic_mean_loss: 0.53173 | prediction_mean_pearson: 0.84657 | prediction_mean_spearman: 0.77066 | entropy_spearman: 0.47197 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 93.00000 | arithmetic_mean_loss: 0.09483 | harmonic_mean_loss: 0.53047 | prediction_mean_pearson: 0.84698 | prediction_mean_spearman: 0.77118 | entropy_spearman: 0.47269 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 94.00000 | arithmetic_mean_loss: 0.09483 | harmonic_mean_loss: 0.53048 | prediction_mean_pearson: 0.84700 | prediction_mean_spearman: 0.77117 | entropy_spearman: 0.47267 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 95.00000 | arithmetic_mean_loss: 0.09486 | harmonic_mean_loss: 0.53137 | prediction_mean_pearson: 0.84683 | prediction_mean_spearman: 0.77080 | entropy_spearman: 0.47269 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BassetBranched(linear_dropout_p=0.11625456877954289,\n",
    "                      branched_activation='ReLU', branched_channels=140,\n",
    "                      branched_dropout_p=0.5757068086404574, \n",
    "                       n_outputs=len(train_dataset[0][1]),\n",
    "                      n_linear_layers=1, n_branched_layers=3, use_batch_norm=True,\n",
    "                      loss_criterion=L1KLmixed(beta=5.0, reduction='mean'))\n",
    "seq_model = CNNTransferLearning(model = model,\n",
    "    parent_weights = \"gs://tewhey-public-data/CODA_resources/my-model.epoch_5-step_19885.pkl\",\n",
    "                       frozen_epochs = 0,\n",
    "                          optimizer = \"Adam\",\n",
    "                          scheduler=\"CosineAnnealingWarmRestarts\",\n",
    "                          scheduler_interval=\"step\")\n",
    "\n",
    "callback_topmodel = pl.callbacks.ModelCheckpoint(monitor=\"prediction_mean_pearson\",\n",
    "                                                 save_top_k=1,\n",
    "                                                 dirpath=\"./Malinois\",\n",
    "                                                 filename=\"Malinois_max\")\n",
    "callback_es = pl.callbacks.early_stopping.EarlyStopping(monitor='prediction_mean_pearson', \n",
    "                                                        patience=30)\n",
    "\n",
    "logger = pl_loggers.TensorBoardLogger(\"./logs_Malinois\", name = \"Malinois_without_rev_augs_with_use_t.Revese(0.5)_200epochs\")\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu', \n",
    "    devices=[0], \n",
    "    min_epochs=60, \n",
    "    max_epochs=200,\n",
    "    precision=16,\n",
    "    enable_progress_bar = False,\n",
    "    callbacks=[\n",
    "        #TQDMProgressBar(refresh_rate=50), \n",
    "        #callback_es, \n",
    "        #callback_topmodel\n",
    "    ],\n",
    "    logger = logger\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(seq_model,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)\n",
    "trainer.test(seq_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafcc3c6-2e0c-448a-902d-4c29fcc24533",
   "metadata": {},
   "source": [
    "# train with RevComp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ec913a-5303-46f6-a139-d21df4726bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "train_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    #t.Reverse(0.5),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "val_test_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "\n",
    "target_transform = t_t.Compose([\n",
    "    #t_t.Normalize(mean = 0.500, std = 1.059) # original for Malinois \n",
    "])\n",
    "activity_columns = ['HepG2','SKNSH', \"K562\"]\n",
    "#stderr = ['lfcSE_k562', 'lfcSE_hepg2', 'lfcSE_sknsh']\n",
    "stderr = ['K562_lfcSE', 'HepG2_lfcSE', 'SKNSH_lfcSE']\n",
    "#seq = \"nt_sequence\"\n",
    "seq = \"sequence\"\n",
    "# load the data\n",
    "train_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, \"Y\"], \n",
    "                                split = \"train\",\n",
    "                              filtration = \"original\",\n",
    "                                duplication_cutoff = 0.5,\n",
    "                                use_reverse_complement = True,\n",
    "                                stderr_columns = stderr,\n",
    "                                sequence_column = seq,\n",
    "                              transform = train_transform,\n",
    "                               target_transform = target_transform) \n",
    "\n",
    "val_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [7, 13], \n",
    "                              split = \"val\",\n",
    "                              filtration = \"original\",\n",
    "                              sequence_column = seq,\n",
    "                              stderr_columns = stderr,\n",
    "                              transform = val_test_transform,\n",
    "                             target_transform = target_transform) \n",
    "\n",
    "test_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [9, 21, \"X\"],\n",
    "                               split = \"test\",\n",
    "                              filtration = \"original\",\n",
    "                               sequence_column = seq,\n",
    "                               stderr_columns = stderr,\n",
    "                              transform = val_test_transform,\n",
    "                              target_transform = target_transform)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = NUM_WORKERS)\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1de282f5-4f67-46dc-9947-55149dd3a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MalinoisDataset of size 1864176 (MpraDaraset)\n",
      "    Number of datapoints: 1864176\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['1', '2', '3', '4', '5', '6', '8', '9', '10', '11', '12', '14', '15', '16', '17', '18', '20', '22', 'Y']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_log2FC', 'SKNSH_log2FC', 'K562_log2FC']\n",
      "    Target columns that can be used: {'SKNSH_log2FC', 'K562_log2FC', 'HepG2_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 58809 (MpraDaraset)\n",
      "    Number of datapoints: 58809\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['19', '21', 'X']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_log2FC', 'SKNSH_log2FC', 'K562_log2FC']\n",
      "    Target columns that can be used: {'SKNSH_log2FC', 'K562_log2FC', 'HepG2_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n",
      "==================================================\n",
      "Dataset MalinoisDataset of size 62582 (MpraDaraset)\n",
      "    Number of datapoints: 62582\n",
      "    Default split folds: {'train': '1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 22, Y', 'val': '19, 21, X', 'test': '7, 13'}\n",
      "    Used split fold: ['7', '13']\n",
      "    Scalar features: {}\n",
      "    Vector features: {}\n",
      "    Cell types: ['HepG2', 'K562', 'SKNSH']\n",
      "    Сell type used: ['HepG2_log2FC', 'SKNSH_log2FC', 'K562_log2FC']\n",
      "    Target columns that can be used: {'SKNSH_log2FC', 'K562_log2FC', 'HepG2_log2FC'}\n",
      "    Number of channels: 4\n",
      "    Sequence size: 600\n",
      "    Number of samples: {'train': 668946, 'val': 62406, 'test': 66712}\n",
      "    Description: MalinoisDataset is based on \n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(\"=\"*50)\n",
    "print(val_dataset)\n",
    "print(\"=\"*50)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b98194-e1fc-4e4b-902f-77f7283596d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4107183 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type           | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model     | BassetBranched | 4.1 M  | train\n",
      "1 | criterion | L1KLmixed      | 0      | train\n",
      "-----------------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.429    Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.14944 | harmonic_mean_loss: 1.70781 | prediction_mean_pearson: -0.01965 | prediction_mean_spearman: -0.04015 | entropy_spearman: 0.02950 |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 0.00000 | arithmetic_mean_loss: 0.14564 | harmonic_mean_loss: 1.30968 | prediction_mean_pearson: 0.57799 | prediction_mean_spearman: 0.46093 | entropy_spearman: 0.10416 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 1.00000 | arithmetic_mean_loss: 0.14316 | harmonic_mean_loss: 1.25912 | prediction_mean_pearson: 0.59319 | prediction_mean_spearman: 0.48198 | entropy_spearman: 0.14444 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 2.00000 | arithmetic_mean_loss: 0.14198 | harmonic_mean_loss: 1.22699 | prediction_mean_pearson: 0.60151 | prediction_mean_spearman: 0.49295 | entropy_spearman: 0.16415 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 3.00000 | arithmetic_mean_loss: 0.14142 | harmonic_mean_loss: 1.21477 | prediction_mean_pearson: 0.60616 | prediction_mean_spearman: 0.49783 | entropy_spearman: 0.17526 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 4.00000 | arithmetic_mean_loss: 0.14115 | harmonic_mean_loss: 1.23405 | prediction_mean_pearson: 0.60218 | prediction_mean_spearman: 0.48587 | entropy_spearman: 0.18734 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 5.00000 | arithmetic_mean_loss: 0.14067 | harmonic_mean_loss: 1.23592 | prediction_mean_pearson: 0.60387 | prediction_mean_spearman: 0.48789 | entropy_spearman: 0.19485 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 6.00000 | arithmetic_mean_loss: 0.14044 | harmonic_mean_loss: 1.22183 | prediction_mean_pearson: 0.60393 | prediction_mean_spearman: 0.49263 | entropy_spearman: 0.19994 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 7.00000 | arithmetic_mean_loss: 0.14021 | harmonic_mean_loss: 1.21317 | prediction_mean_pearson: 0.60464 | prediction_mean_spearman: 0.49579 | entropy_spearman: 0.20413 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 8.00000 | arithmetic_mean_loss: 0.14055 | harmonic_mean_loss: 1.20589 | prediction_mean_pearson: 0.60116 | prediction_mean_spearman: 0.49713 | entropy_spearman: 0.20585 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 9.00000 | arithmetic_mean_loss: 0.14047 | harmonic_mean_loss: 1.20432 | prediction_mean_pearson: 0.60153 | prediction_mean_spearman: 0.49815 | entropy_spearman: 0.20862 |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 10.00000 | arithmetic_mean_loss: 0.14036 | harmonic_mean_loss: 1.20976 | prediction_mean_pearson: 0.60059 | prediction_mean_spearman: 0.49679 | entropy_spearman: 0.21075 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 11.00000 | arithmetic_mean_loss: 0.14030 | harmonic_mean_loss: 1.21387 | prediction_mean_pearson: 0.59990 | prediction_mean_spearman: 0.49651 | entropy_spearman: 0.21268 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 12.00000 | arithmetic_mean_loss: 0.14063 | harmonic_mean_loss: 1.21201 | prediction_mean_pearson: 0.59717 | prediction_mean_spearman: 0.49693 | entropy_spearman: 0.21364 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 13.00000 | arithmetic_mean_loss: 0.14112 | harmonic_mean_loss: 1.21213 | prediction_mean_pearson: 0.59374 | prediction_mean_spearman: 0.49672 | entropy_spearman: 0.21420 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 14.00000 | arithmetic_mean_loss: 0.14140 | harmonic_mean_loss: 1.21188 | prediction_mean_pearson: 0.59222 | prediction_mean_spearman: 0.49693 | entropy_spearman: 0.21509 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 15.00000 | arithmetic_mean_loss: 0.14140 | harmonic_mean_loss: 1.21389 | prediction_mean_pearson: 0.59168 | prediction_mean_spearman: 0.49642 | entropy_spearman: 0.21578 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 16.00000 | arithmetic_mean_loss: 0.14149 | harmonic_mean_loss: 1.21542 | prediction_mean_pearson: 0.59095 | prediction_mean_spearman: 0.49652 | entropy_spearman: 0.21567 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 17.00000 | arithmetic_mean_loss: 0.14170 | harmonic_mean_loss: 1.21683 | prediction_mean_pearson: 0.58970 | prediction_mean_spearman: 0.49650 | entropy_spearman: 0.21614 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 18.00000 | arithmetic_mean_loss: 0.14226 | harmonic_mean_loss: 1.22114 | prediction_mean_pearson: 0.58641 | prediction_mean_spearman: 0.49568 | entropy_spearman: 0.21570 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 19.00000 | arithmetic_mean_loss: 0.14264 | harmonic_mean_loss: 1.22439 | prediction_mean_pearson: 0.58433 | prediction_mean_spearman: 0.49561 | entropy_spearman: 0.21628 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 20.00000 | arithmetic_mean_loss: 0.14276 | harmonic_mean_loss: 1.22637 | prediction_mean_pearson: 0.58353 | prediction_mean_spearman: 0.49546 | entropy_spearman: 0.21618 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 21.00000 | arithmetic_mean_loss: 0.14335 | harmonic_mean_loss: 1.23222 | prediction_mean_pearson: 0.58061 | prediction_mean_spearman: 0.49472 | entropy_spearman: 0.21574 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 22.00000 | arithmetic_mean_loss: 0.14375 | harmonic_mean_loss: 1.23575 | prediction_mean_pearson: 0.57899 | prediction_mean_spearman: 0.49433 | entropy_spearman: 0.21565 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 23.00000 | arithmetic_mean_loss: 0.14382 | harmonic_mean_loss: 1.23745 | prediction_mean_pearson: 0.57844 | prediction_mean_spearman: 0.49411 | entropy_spearman: 0.21570 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 24.00000 | arithmetic_mean_loss: 0.14398 | harmonic_mean_loss: 1.23919 | prediction_mean_pearson: 0.57784 | prediction_mean_spearman: 0.49415 | entropy_spearman: 0.21597 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 25.00000 | arithmetic_mean_loss: 0.14397 | harmonic_mean_loss: 1.24240 | prediction_mean_pearson: 0.57679 | prediction_mean_spearman: 0.49313 | entropy_spearman: 0.21602 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 26.00000 | arithmetic_mean_loss: 0.14435 | harmonic_mean_loss: 1.24674 | prediction_mean_pearson: 0.57521 | prediction_mean_spearman: 0.49301 | entropy_spearman: 0.21607 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 27.00000 | arithmetic_mean_loss: 0.14439 | harmonic_mean_loss: 1.25368 | prediction_mean_pearson: 0.57260 | prediction_mean_spearman: 0.49015 | entropy_spearman: 0.21580 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 28.00000 | arithmetic_mean_loss: 0.14450 | harmonic_mean_loss: 1.25567 | prediction_mean_pearson: 0.57183 | prediction_mean_spearman: 0.48988 | entropy_spearman: 0.21573 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 29.00000 | arithmetic_mean_loss: 0.14456 | harmonic_mean_loss: 1.25736 | prediction_mean_pearson: 0.57135 | prediction_mean_spearman: 0.48963 | entropy_spearman: 0.21589 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 30.00000 | arithmetic_mean_loss: 0.14462 | harmonic_mean_loss: 1.25903 | prediction_mean_pearson: 0.57086 | prediction_mean_spearman: 0.48928 | entropy_spearman: 0.21583 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 31.00000 | arithmetic_mean_loss: 0.14466 | harmonic_mean_loss: 1.26082 | prediction_mean_pearson: 0.57028 | prediction_mean_spearman: 0.48906 | entropy_spearman: 0.21585 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 32.00000 | arithmetic_mean_loss: 0.14487 | harmonic_mean_loss: 1.26310 | prediction_mean_pearson: 0.56944 | prediction_mean_spearman: 0.48898 | entropy_spearman: 0.21576 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 33.00000 | arithmetic_mean_loss: 0.14501 | harmonic_mean_loss: 1.26496 | prediction_mean_pearson: 0.56883 | prediction_mean_spearman: 0.48892 | entropy_spearman: 0.21578 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 34.00000 | arithmetic_mean_loss: 0.14503 | harmonic_mean_loss: 1.26944 | prediction_mean_pearson: 0.56719 | prediction_mean_spearman: 0.48714 | entropy_spearman: 0.21561 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 35.00000 | arithmetic_mean_loss: 0.14519 | harmonic_mean_loss: 1.27146 | prediction_mean_pearson: 0.56651 | prediction_mean_spearman: 0.48710 | entropy_spearman: 0.21578 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 36.00000 | arithmetic_mean_loss: 0.14534 | harmonic_mean_loss: 1.27325 | prediction_mean_pearson: 0.56598 | prediction_mean_spearman: 0.48714 | entropy_spearman: 0.21586 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 37.00000 | arithmetic_mean_loss: 0.14542 | harmonic_mean_loss: 1.27459 | prediction_mean_pearson: 0.56561 | prediction_mean_spearman: 0.48716 | entropy_spearman: 0.21605 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 38.00000 | arithmetic_mean_loss: 0.14545 | harmonic_mean_loss: 1.27645 | prediction_mean_pearson: 0.56499 | prediction_mean_spearman: 0.48672 | entropy_spearman: 0.21614 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 39.00000 | arithmetic_mean_loss: 0.14553 | harmonic_mean_loss: 1.27798 | prediction_mean_pearson: 0.56454 | prediction_mean_spearman: 0.48664 | entropy_spearman: 0.21619 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 40.00000 | arithmetic_mean_loss: 0.14575 | harmonic_mean_loss: 1.28059 | prediction_mean_pearson: 0.56367 | prediction_mean_spearman: 0.48650 | entropy_spearman: 0.21607 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 41.00000 | arithmetic_mean_loss: 0.14586 | harmonic_mean_loss: 1.28224 | prediction_mean_pearson: 0.56321 | prediction_mean_spearman: 0.48638 | entropy_spearman: 0.21615 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 42.00000 | arithmetic_mean_loss: 0.14597 | harmonic_mean_loss: 1.28405 | prediction_mean_pearson: 0.56257 | prediction_mean_spearman: 0.48614 | entropy_spearman: 0.21602 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 43.00000 | arithmetic_mean_loss: 0.14607 | harmonic_mean_loss: 1.28567 | prediction_mean_pearson: 0.56208 | prediction_mean_spearman: 0.48599 | entropy_spearman: 0.21607 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 44.00000 | arithmetic_mean_loss: 0.14631 | harmonic_mean_loss: 1.28851 | prediction_mean_pearson: 0.56126 | prediction_mean_spearman: 0.48589 | entropy_spearman: 0.21600 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 45.00000 | arithmetic_mean_loss: 0.14650 | harmonic_mean_loss: 1.29093 | prediction_mean_pearson: 0.56053 | prediction_mean_spearman: 0.48570 | entropy_spearman: 0.21596 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 46.00000 | arithmetic_mean_loss: 0.14661 | harmonic_mean_loss: 1.29252 | prediction_mean_pearson: 0.56009 | prediction_mean_spearman: 0.48558 | entropy_spearman: 0.21592 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 47.00000 | arithmetic_mean_loss: 0.14667 | harmonic_mean_loss: 1.29380 | prediction_mean_pearson: 0.55976 | prediction_mean_spearman: 0.48538 | entropy_spearman: 0.21599 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 48.00000 | arithmetic_mean_loss: 0.14692 | harmonic_mean_loss: 1.29700 | prediction_mean_pearson: 0.55893 | prediction_mean_spearman: 0.48527 | entropy_spearman: 0.21596 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 49.00000 | arithmetic_mean_loss: 0.14695 | harmonic_mean_loss: 1.29841 | prediction_mean_pearson: 0.55840 | prediction_mean_spearman: 0.48489 | entropy_spearman: 0.21593 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 50.00000 | arithmetic_mean_loss: 0.14704 | harmonic_mean_loss: 1.29978 | prediction_mean_pearson: 0.55804 | prediction_mean_spearman: 0.48480 | entropy_spearman: 0.21594 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 51.00000 | arithmetic_mean_loss: 0.14714 | harmonic_mean_loss: 1.30139 | prediction_mean_pearson: 0.55759 | prediction_mean_spearman: 0.48459 | entropy_spearman: 0.21592 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 52.00000 | arithmetic_mean_loss: 0.14739 | harmonic_mean_loss: 1.30427 | prediction_mean_pearson: 0.55683 | prediction_mean_spearman: 0.48441 | entropy_spearman: 0.21593 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| current_epoch: 53.00000 | arithmetic_mean_loss: 0.14750 | harmonic_mean_loss: 1.30579 | prediction_mean_pearson: 0.55650 | prediction_mean_spearman: 0.48436 | entropy_spearman: 0.21598 |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BassetBranched(linear_dropout_p=0.11625456877954289,\n",
    "                      branched_activation='ReLU', branched_channels=140,\n",
    "                      branched_dropout_p=0.5757068086404574, \n",
    "                       n_outputs=len(train_dataset[0][1]),\n",
    "                      n_linear_layers=1, n_branched_layers=3, use_batch_norm=True,\n",
    "                      loss_criterion=L1KLmixed(beta=5.0, reduction='mean'))\n",
    "seq_model = CNNTransferLearning(model = model,\n",
    "                                lr = 3e-4, weight_decay = 0.01,\n",
    "    parent_weights = \"gs://tewhey-public-data/CODA_resources/my-model.epoch_5-step_19885.pkl\",\n",
    "                       frozen_epochs = 0,\n",
    "                          optimizer = \"AdamW\",\n",
    "                          scheduler=\"OneCycleLR\",\n",
    "                          scheduler_interval=\"step\")\n",
    "\n",
    "callback_topmodel = pl.callbacks.ModelCheckpoint(monitor=\"prediction_mean_pearson\",\n",
    "                                                 save_top_k=1,\n",
    "                                                 dirpath=\"./Malinois\",\n",
    "                                                 filename=\"Malinois_max\",\n",
    "                                                mode = \"max\")\n",
    "callback_es = pl.callbacks.early_stopping.EarlyStopping(monitor='prediction_mean_pearson', \n",
    "                                                        patience=30)\n",
    "\n",
    "logger = pl_loggers.TensorBoardLogger(\"./logs_Malinois\", name = \"Malinois_without_rev_augs_with_use_t.Revese(0.5)_200epochs\")\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu', \n",
    "    devices=[0], \n",
    "    min_epochs=60, \n",
    "    max_epochs=200,\n",
    "    precision=16,\n",
    "    enable_progress_bar = False,\n",
    "    callbacks=[\n",
    "        #TQDMProgressBar(refresh_rate=50), \n",
    "        callback_es, \n",
    "        #callback_topmodel\n",
    "    ],\n",
    "    #logger = logger\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(seq_model,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)\n",
    "trainer.test(seq_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f152a-a746-4c32-a7f8-b1c3cea968a2",
   "metadata": {},
   "source": [
    "# Lr finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a9546c7-53ed-4616-807a-98b5773e9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "train_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    #t.Reverse(0.5),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "val_test_transform = t.Compose([\n",
    "    t.AddFlanks(left_flank, right_flank),\n",
    "    t.CenterCrop(600),\n",
    "    t.Seq2Tensor()\n",
    "])\n",
    "\n",
    "target_transform = t_t.Compose([\n",
    "    #t_t.Normalize(mean = 0.500, std = 1.059) # original for Malinois \n",
    "])\n",
    "activity_columns = ['HepG2','SKNSH', \"K562\"]\n",
    "#stderr = ['lfcSE_k562', 'lfcSE_hepg2', 'lfcSE_sknsh']\n",
    "stderr = ['K562_lfcSE', 'HepG2_lfcSE', 'SKNSH_lfcSE']\n",
    "#seq = \"nt_sequence\"\n",
    "seq = \"sequence\"\n",
    "# load the data\n",
    "train_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, \"Y\"], \n",
    "                                split = \"train\",\n",
    "                              filtration = \"original\",\n",
    "                                duplication_cutoff = 0.5,\n",
    "                                use_reverse_complement = True,\n",
    "                                stderr_columns = stderr,\n",
    "                                sequence_column = seq,\n",
    "                              transform = train_transform,\n",
    "                               target_transform = target_transform) \n",
    "\n",
    "val_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [7, 13], \n",
    "                              split = \"val\",\n",
    "                              filtration = \"original\",\n",
    "                              sequence_column = seq,\n",
    "                              stderr_columns = stderr,\n",
    "                              transform = val_test_transform,\n",
    "                             target_transform = target_transform) \n",
    "\n",
    "test_dataset = MalinoisDataset(activity_columns = activity_columns, \n",
    "                              #split = [9, 21, \"X\"],\n",
    "                               split = \"test\",\n",
    "                              filtration = \"original\",\n",
    "                               sequence_column = seq,\n",
    "                               stderr_columns = stderr,\n",
    "                              transform = val_test_transform,\n",
    "                              target_transform = target_transform)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = NUM_WORKERS)\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b2a27c1-a4b1-48f8-bba5-b50b00d949bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nios/miniconda3/envs/mpra/lib/python3.12/site-packages/torch_lr_finder/lr_finder.py:5: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc393181-4678-48c8-a0c0-8d2c327c75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BassetBranched(linear_dropout_p=0.11625456877954289,\n",
    "                      branched_activation='ReLU', branched_channels=140,\n",
    "                      branched_dropout_p=0.5757068086404574, \n",
    "                       n_outputs=len(train_dataset[0][1]),\n",
    "                      n_linear_layers=1, n_branched_layers=3, use_batch_norm=True,\n",
    "                      loss_criterion=L1KLmixed(beta=5.0, reduction='mean'))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-7, weight_decay = 0.01,)\n",
    "criterion=L1KLmixed(beta=5.0, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cef9f7fd-f798-4256-9588-2da595fe1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "962eb336-be22-4cc6-bb10-0711af821d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/100 [00:00<?, ?it/s]/home/nios/miniconda3/envs/mpra/lib/python3.12/site-packages/torch/nn/functional.py:2994: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 80/100 [00:15<00:03,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    }
   ],
   "source": [
    "lr_finder.range_test(train_loader, start_lr=1e-6, end_lr=10, num_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8930c2e8-3760-4f8f-92e8-79f2292356b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 5.72E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.plot()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19a04f82-95aa-44e0-9e33-68b1e756169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nios/miniconda3/envs/mpra/lib/python3.12/site-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = BassetBranched(linear_dropout_p=0.11625456877954289,\n",
    "                      branched_activation='ReLU', branched_channels=140,\n",
    "                      branched_dropout_p=0.5757068086404574, \n",
    "                       n_outputs=len(train_dataset[0][1]),\n",
    "                      n_linear_layers=1, n_branched_layers=3, use_batch_norm=True,\n",
    "                      loss_criterion=L1KLmixed(beta=5.0, reduction='mean'))\n",
    "seq_model = CNNTransferLearning(model = model,\n",
    "                                lr = 5.72e-04, weight_decay = 0.01,\n",
    "    parent_weights = \"gs://tewhey-public-data/CODA_resources/my-model.epoch_5-step_19885.pkl\",\n",
    "                       frozen_epochs = 0,\n",
    "                          optimizer = \"AdamW\",\n",
    "                          scheduler=\"OneCycleLR\",\n",
    "                          scheduler_interval=\"step\")\n",
    "\n",
    "callback_topmodel = pl.callbacks.ModelCheckpoint(monitor=\"prediction_mean_pearson\",\n",
    "                                                 save_top_k=1,\n",
    "                                                 dirpath=\"./Malinois\",\n",
    "                                                 filename=\"Malinois_max\",\n",
    "                                                mode = \"max\")\n",
    "callback_es = pl.callbacks.early_stopping.EarlyStopping(monitor='prediction_mean_pearson', \n",
    "                                                        patience=30)\n",
    "\n",
    "logger = pl_loggers.TensorBoardLogger(\"./logs_Malinois\", name = \"Malinois_after_lr_finder(5.72e-04)\")\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu', \n",
    "    devices=[0], \n",
    "    min_epochs=60, \n",
    "    max_epochs=200,\n",
    "    precision=16,\n",
    "    enable_progress_bar = False,\n",
    "    callbacks=[\n",
    "        #TQDMProgressBar(refresh_rate=50), \n",
    "        callback_es, \n",
    "        #callback_topmodel\n",
    "    ],\n",
    "    #logger = logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e1cdc-4d13-481b-bce0-392eafdf56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792224f-eccd-4d36-a5ce-3361288b404b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mpra]",
   "language": "python",
   "name": "conda-env-mpra-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
