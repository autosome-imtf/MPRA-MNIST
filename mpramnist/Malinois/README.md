# Malinois dataset

## Main Information 

The Malinois dataset is based on a large-scale, uniformly processed database of MPRA experiments used to train the Malinois model ([Gosai et al. 2023](https://pmc.ncbi.nlm.nih.gov/articles/PMC10441439/)). It aggregates 798,064 oligonucleotides tested across three cell lines: K562, HepG2, and SK-N-SH. The dataset includes both natural sequences derived from the human genome and synthetic sequences generated by the model during its design cycle.

Following Gosai et al. 2023, we use sequences from chromosomes 7 and 13 for testing (~13% of all sequences), chromosomes 19, 21, and X for validation (~7%), and all other chromosomes for training.

Key preprocessing steps (as per the original study):

- **Padding**: Each sequence should be padded on both sides with constant vector flanks to a total length of 600 bp.

- **Augmentation**: Add reverse-complement sequences to the training set. The dataset size is doubles.

- **Enrichment**: Duplicate sequences with an absolute log2FC value > 0.5 in any cell line to increase their weight during training.

These steps are demonstrated in the dataset usage example: [MalinoisDataset_example.ipynb](https://github.com/autosome-imtf/MPRA-MNIST/blob/main/examples/Malinois_Dataset_example_model_legnet.ipynb).

## Tasks

### Regression

The core task is a multi-output regression problem. For any given DNA sequence (approximately 200 bp, optionally padded), the goal is to predict its regulatory activity across three human cell lines: K562, HepG2, and SK-N-SH.

### Data Representation

```
seq_id	            chromosome	start	    end	        strand	sequence_length	data_project	OL	class	        sequence	    K562_log2FC	        HepG2_log2FC	    SKNSH_log2FC	    K562_lfcSE	        HepG2_lfcSE	        SKNSH_lfcSE
7:70038969:G:T:A:wC	    7	    70038869	70039069	+	        200	            UKBB        29	BMI,BFP	        CCTGGTCTTT...	0.0607792388454394	0.233600760180268	0.0471937437039324  0.0987954468253551	0.118253548331248	0.130670619322498
1:192696196:C:T:A:wC	1	    192696096	192696296	+	        200	            UKBB	    33	Depression_GP	CATAAAGATG...	0.3796391272646789	0.0045654428683256	-0.244395088866995	0.162168818107855	0.186394373745978	0.11895171042174
1:211209457:C:T:A:wC	1	    211209357	211209557	+	        200	            UKBB	    33	CAD	            CATAAAGCCA...	0.0367073155744713	0.384537006161859	-0.0045776378436509	0.0983907534939833	0.121639615330522	0.0874575351503177
```

## Parameters

### **`split : str | List[Union[int, str]] | int`**

Specifies the data split to use. Can be:
- String: `'train'`, `'val'`, `'test'` (uses predefined chromosome sets: train - all except specified below, test - chr7,13, val - chr19,21,X)
- List[str]: List of specific chromosomes (e.g., `['1', '2', 'X']`)
- List[int]: List of chromosome numbers (1-22)
- int: Single chromosome number (1-22)

### **`genomic_regions : str | List[Dict], optional`**

Genomic regions to include/exclude. Can be:
- str: Path to BED file containing genomic regions (hg19, 0-based)
- List[Dict]: List of dictionaries with 'chrom', 'start', 'end' keys (hg19, 0-based)

### **`exclude_regions : bool`**, default=`False`

If `True`, exclude the specified regions instead of including them.

### **`genomic_regions_column : List[str]`**, default=`["start", "end", "strand"]`

Column names containing genomic position information.

### **`filtration : str`**, default=`"original"`

Specifies the filtering method. Options are:
- `'original'`: Applies the original study's pipeline: padding to 600bp with constant flanks, quality filtering based on standard error, and activity-based sequence duplication. **When using this, do NOT apply `AddFlanks` transforms externally**.
- `'own'`: Applies custom filtering using the `stderr_threshold`, `std_multiple_cut`, `up_cutoff_move`, `duplication_cutoff` parameters. Padding and reverse complement must be handled manually via transforms.
- `'none'`: No filtering is applied. All data handling (padding, augmentation) must be done manually.

### **`cell_type : List[str]`**, default=`["K562_log2FC", "HepG2_log2FC", "SKNSH_log2FC"]`

List of column names with activity data to be used for filtering and duplication.

### **`stderr_columns : List[str]`**, default=`["K562_lfcSE", "HepG2_lfcSE", "SKNSH_lfcSE"]`

List of column names with standard error values used for quality filtering when `filtration` is `'original'` or `'own'`.

### **`data_project : List[str]`**, default=`["UKBB", "GTEX", "CRE"]`

Specifies the data projects to include in filtering.

### **`sequence_column : str`**, default=`"sequence"`

Name of the column containing DNA sequences.

### **`duplication_cutoff : Optional[float]`**, optional

If specified, sequences with an absolute activity value above this threshold in any of the selected `cell_type` columns will be duplicated in the training set (mirroring the original study's enrichment). Typically used only for the `split="train"`.

### **`stderr_threshold : float`**, default=`1.0`

Maximum allowed standard error for a sequence to be included (used in `filtration='own'`).

### **`std_multiple_cut : float`**, default=`6.0`

The multiplier applied to the standard deviation to calculate the upper bound for outlier filtering in `filtration='own'`.

### **`up_cutoff_move : float`**, default=`3.0`

Shift value for adjusting the upper bound cutoff in `filtration='own'`.

### **`transform : Optional[Callable]`**, optional

A transformation function applied to each sequence sample (e.g., converting to a tensor).

### **`target_transform : Optional[Callable]`**, optional

Transformation function applied to the target data.

### **`use_original_reverse_complement : bool`**, default=`False`

**Important**: This controls built-in augmentation from the original paper.

If `True`: The dataset internally returns an augmented set for the `"train"` split (original + reverse complement). The dataset length doubles. **Do not apply an external `ReverseComplement` transform in this case, as it will cause data leakage.**.

If `False` (Default): The dataset returns original sequences. You can then apply your own `ReverseComplement` transform via the `transform` parameter (e.g., with a probability of 0.5 for training).

### **`root`** : optional

Root directory for data storage.

## Data Handling Considerations

1) **Cell Type Selection**: Use the `cell_type` parameter to select one or multiple cell lines (K562, HepG2, SK-N-SH) for modeling. This defines the output dimensionality.

2) **Multi-task Learning**: This dataset is designed for multi-task learning, where a single model predicts activities across multiple cell lines simultaneously.

3) **Filtration Logic**: The `filtration` parameter dictates the preprocessing pipeline. Choose `filtration = 'original'` (and `use_original_reverse_complement = True`) to replicate the paper's methods, `filtration = 'own'` for custom filtering, or `filtration = 'none'` for raw data.

4) **Reverse Complement Augmentation**: Carefully manage the `use_original_reverse_complement` parameter and external `ReverseComplement` transforms to avoid duplicating data incorrectly. Use only one method.

5) **Genomic Region Filtering**: Use `the genomic_regions` and `exclude_regions` parameters to select or exclude specific genomic regions across chromosomes. Uses **0-based** indexing for genomic coordinates in **hg19**.

6) **Constant Flanks**: The original study padded all sequences to 600bp using constant flanking sequences. These flanks are available as class attributes: `MalinoisDataset.LEFT_FLANK` and `MalinoisDataset.RIGHT_FLANK`. **If you use `filtration='original'`, flanks are added automatically. For `'own'` or `'none'`, you must add them manually using the `AddFlanks` transform**.

7) **Example Usage**: See [Usage Example](https://github.com/autosome-imtf/MPRA-MNIST/blob/main/examples/Malinois_Dataset_example_model_legnet.ipynb) for detailed usage example and training

## Examples

### 1) Import Important Packages

```python
    import mpramnist
    from mpramnist.DeepStarr.dataset import DeepStarrDataset
    import torch.utils.data as data
    import mpramnist.transforms as t

    left_flank = MalinoisDataset.LEFT_FLANK
    right_flank = MalinoisDataset.RIGHT_FLANK
```

### 2) Initialize transforms

```python

    # For ORIGINAL filtration (flanks handled internally)
    transform_to_tensor = t.Compose([t.Seq2Tensor()])

    # For OWN or NONE filtration (handle flanks and augmentation manually)
    train_transform_not_original = t.Compose(
    [
        t.AddFlanks(left_flank, right_flank),
        t.CenterCrop(230),
        t.ReverseComplement(0.5), # reverse-complement for training
        t.Seq2Tensor(),
    ])

    val_transform_not_original = t.Compose(
    [
        t.AddFlanks(left_flank, right_flank),
        t.CenterCrop(230),
        t.ReverseComplement(0.0), # no reverse-complement for validation and test
        t.Seq2Tensor(),
    ])


```

### 3) Dataset Creation

```python
    # Example 1: Training with original pipeline
    train_dataset = MalinoisDataset(
        split="train",
        filtration="original", 
        duplication_cutoff=0.5,  # Enrich high-activity sequences
        use_original_reverse_complement=True,  # Internal rev-comp augmentation
        transform=transform_to_tensor, # Just convert to tensor
        root="../data/",
    )
    # Example 2: Validation on specific chromosomes with custom filtering
    val_dataset = MalinoisDataset(
         split=['1', '2', '3'],
         filtration='own',
         stderr_threshold=0.8,
         transform = val_transform_not_original, # Manually add flanks, no rev-comp
         root = "../data/"
    )

    # Example 3: Excluding specific genomic regions from training
    test_regions = [
        {"chrom": "10", "start": 1, "end": 1000000000},
        {"chrom": "1", "start": 1, "end": 1000000000},
        {"chrom": "X", "start": 1, "end": 1000000000},
    ]
    train_dataset = MalinoisDataset(
        split="train",
        filtration="none",
        root="../data/",
        genomic_regions=test_regions,
        exclude_regions=True,  # Exclude these regions
        transform = train_transform_not_original  # Handle all preprocessing manually
    )

```

### 4) Dataloader Creation

```python 
    train_loader = data.DataLoader(
        dataset=train_dataset, 
        batch_size=1024, 
        shuffle=True,      # Shuffle is recommended for training
        num_workers=8
    )

    val_loader = data.DataLoader(
        dataset=val_dataset, 
        batch_size=1024, 
        shuffle=False,      # No need to shuffle for validation/testing
        num_workers=8
    )
```


## Original Benchmark Quality

Pearson correlation, r

 - r = 0,89 for **HepG2**

 - r = 0,88 for **K562**

 - r = 0,88 for **SK-N-SH**


## Achieved Quality Using LegNet Model in MPRA-MNIST

Pearson correlation, r

 - r = 0,908 for **HepG2**

 - r = 0,908 for **K562**

 - r = 0,898 for **SK-N-SH**

## Citation

When using this dataset, please cite the original publication:

[Gosai et al. 2023](https://pmc.ncbi.nlm.nih.gov/articles/PMC10441439/)

Gosai SJ, Castro RI, Fuentes N, Butts JC, Kales S, Noche RR, Mouri K, Sabeti PC, Reilly SK, Tewhey R. Machine-guided design of synthetic cell type-specific cis-regulatory elements. bioRxiv [Preprint]. 2023 Aug 9:2023.08.08.552077. doi: 10.1101/2023.08.08.552077. Update in: Nature. 2024 Oct;634(8036):1211-1220. doi: 10.1038/s41586-024-08070-z. PMID: 37609287; PMCID: PMC10441439.

```bibtex
    @article{Gosai2024machine,
        title = {Machine-guided design of synthetic cell type-specific cis-regulatory elements},
        author = {Gosai, Sager J. and Castro, Raymund I. and Fuentes, Nicol{\'a}s and Butts, Jacob C. and Kales, Scott and Noche, Ramil R. and Mouri, Kana and Sabeti, Pardis C. and Reilly, Steven K. and Tewhey, Ryan},
        journal = {Nature},
        year = {2024},
        month = {Oct},
        volume = {634},
        number = {8036},
        pages = {1211--1220},
        doi = {10.1038/s41586-024-08070-z}
    }
```